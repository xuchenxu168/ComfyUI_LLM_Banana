import os
import base64
import io
import json
import torch
import numpy as np
from PIL import Image
import requests
from io import BytesIO
import traceback
import tempfile
import wave
import random
import time
from typing import Tuple

try:
    from server import PromptServer
except Exception:
    PromptServer = None

def _log_info(message):
    try:
        print(f"[LLM Agent Assistant][Gemini-Banana] {message}")
    except UnicodeEncodeError:
        print(f"[LLM Prompt][Gemini-Banana] INFO: {repr(message)}")

def _log_warning(message):
    try:
        print(f"[LLM Agent Assistant][Gemini-Banana] WARNING: {message}")
    except UnicodeEncodeError:
        print(f"[LLM Prompt][Gemini-Banana] WARNING: {repr(message)}")

def _log_error(message):
    try:
        print(f"[LLM Agent Assistant][Gemini-Banana] ERROR: {message}")
    except UnicodeEncodeError:
        print(f"[LLM Prompt][Gemini-Banana] ERROR: {repr(message)}")

def smart_retry_delay(attempt, error_code=None):
    """æ™ºèƒ½é‡è¯•å»¶è¿Ÿ - æ ¹æ®é”™è¯¯ç±»å‹è°ƒæ•´ç­‰å¾…æ—¶é—´"""
    base_delay = 2 ** attempt  # æŒ‡æ•°é€€é¿
    
    if error_code == 429:  # é™æµé”™è¯¯
        # å¯¹äº429é”™è¯¯ï¼Œä½¿ç”¨æ›´é•¿çš„ç­‰å¾…æ—¶é—´
        rate_limit_delay = 60 + random.uniform(10, 30)  # 60-90ç§’éšæœºç­‰å¾…
        return max(base_delay, rate_limit_delay)
    elif error_code in [500, 502, 503, 504]:  # æœåŠ¡å™¨é”™è¯¯
        return base_delay + random.uniform(1, 5)  # æ·»åŠ éšæœºæŠ–åŠ¨
    else:
        return base_delay

def resize_image_for_api(image, max_size=2048):
    """è°ƒæ•´å›¾åƒå¤§å°ä»¥æ»¡è¶³APIé™åˆ¶"""
    if max(image.size) > max_size:
        ratio = max_size / max(image.size)
        new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))
        image = image.resize(new_size, Image.Resampling.LANCZOS)
        _log_info(f"Image resized to {new_size} for API compatibility")
    return image

def process_image_controls(size: str, quality: str, style: str, custom_size: str = "") -> dict:
    """
    å¤„ç†å›¾åƒæ§åˆ¶å‚æ•°ï¼Œè¿”å›æ ‡å‡†åŒ–çš„æ§åˆ¶é…ç½®
    
    Args:
        size: é¢„è®¾å°ºå¯¸
        quality: è´¨é‡è®¾ç½®
        style: é£æ ¼è®¾ç½®
        custom_size: è‡ªå®šä¹‰å°ºå¯¸
        
    Returns:
        dict: åŒ…å«å¤„ç†åçš„å›¾åƒæ§åˆ¶å‚æ•°
    """
    # å¤„ç†å°ºå¯¸
    final_size = custom_size.strip() if custom_size and custom_size.strip() else size
    
    # éªŒè¯è‡ªå®šä¹‰å°ºå¯¸æ ¼å¼
    if custom_size and custom_size.strip():
        import re
        size_pattern = r'^\d+x\d+$'
        if not re.match(size_pattern, custom_size.strip()):
            print(f"âš ï¸ è‡ªå®šä¹‰å°ºå¯¸æ ¼å¼æ— æ•ˆ: {custom_size}ï¼Œä½¿ç”¨é¢„è®¾å°ºå¯¸: {size}")
            final_size = size
    
    # æ„å»ºæ§åˆ¶é…ç½®
    controls = {
        "size": final_size,
        "quality": quality,
        "style": style,
        "is_custom_size": bool(custom_size and custom_size.strip())
    }
    
    return controls


def enhance_prompt_with_controls(prompt: str, controls: dict) -> str:
    """
    ä½¿ç”¨å›¾åƒæ§åˆ¶å‚æ•°å¢å¼ºæç¤ºè¯ï¼Œå‚è€ƒ OpenRouter çš„å®ç°æ–¹å¼

    å½“ style ä¸º None/ç©ºå­—ç¬¦ä¸² æ—¶ï¼Œä¸åœ¨æç¤ºè¯ä¸­å†™å…¥é£æ ¼è¦æ±‚ã€‚
    """
    size_line = f"1. è¾“å‡ºå°ºå¯¸ï¼š{controls['size']}"
    quality_line = f"2. è´¨é‡ï¼š{'é«˜è´¨é‡' if controls['quality'] == 'hd' else 'æ ‡å‡†è´¨é‡'}"

    style_raw = str(controls.get('style', '') or '').strip().lower()
    style_line = ""
    if style_raw not in ("none", ""):
        # ç®€å•æ˜ å°„ï¼švivid->ç”ŸåŠ¨é£æ ¼ï¼›natural->è‡ªç„¶é£æ ¼ï¼›å…¶ä»–ç›´æ¥æ˜¾ç¤ºåŸå€¼
        if style_raw == "vivid":
            style_text = "ç”ŸåŠ¨é£æ ¼"
        elif style_raw == "natural":
            style_text = "è‡ªç„¶é£æ ¼"
        else:
            style_text = controls.get('style', '')
        style_line = f"3. é£æ ¼ï¼š{style_text}"

    # ç»„è£…è¦æ±‚å—
    lines = [size_line, quality_line]
    if style_line:
        lines.append(style_line)
    req_block = "\n".join(lines)

    enhanced_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒç”Ÿæˆä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ç”Ÿæˆå›¾åƒï¼š

{prompt}

å…·ä½“è¦æ±‚ï¼š
{req_block}

æ„å›¾è¦æ±‚ï¼š
- ä½¿ç”¨å¹³è¡¡çš„æ„å›¾ï¼Œä¸»ä½“ä¸èƒŒæ™¯æ¯”ä¾‹é€‚å½“
- ä¸»ä½“åº”æ¸…æ™°å¯è§ä¸”å®Œæ•´å±•ç°ï¼Œå æ®å›¾åƒé¢ç§¯çš„40-60%
- åŒ…å«ä¸°å¯Œçš„èƒŒæ™¯ç¯å¢ƒå’Œä¸Šä¸‹æ–‡ï¼Œåˆ›é€ å±‚æ¬¡æ„Ÿå’Œæ°›å›´
- ä½¿ç”¨ä¸­æ™¯æ‹æ‘„ï¼Œå±•ç°ä¸»ä½“åœ¨å…¶ç¯å¢ƒä¸­çš„çŠ¶æ€
- é¿å…è¿‡åº¦ç‰¹å†™å’Œè¿‡äºé¥è¿œçš„æ‹æ‘„è§’åº¦
- ç¡®ä¿ä¸»ä½“å®Œå…¨åœ¨ç”»é¢è¾¹ç•Œå†…ä¸”ä¸ç¯å¢ƒå’Œè°ç»Ÿä¸€

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚ç”Ÿæˆå›¾åƒï¼Œç¡®ä¿è¾“å‡ºå°ºå¯¸ã€è´¨é‡å’Œæ„å›¾å®Œå…¨ç¬¦åˆè¦æ±‚ã€‚ä¸è¦æè¿°å›¾ç‰‡ï¼Œç›´æ¥ç”Ÿæˆç¬¦åˆè§„æ ¼çš„å›¾åƒã€‚"""
    return enhanced_prompt


def load_gemini_banana_config():
    """Load Gemini Banana configuration file"""
    config_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "Gemini_Banana_config.json")
    try:
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            _log_info(f"Successfully loaded Gemini Banana config file: {config_path}")
            return config
        else:
            # Use default Gemini config as fallback
            fallback_config_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "Gemini_config.json")
            if os.path.exists(fallback_config_path):
                with open(fallback_config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                _log_info(f"Using default Gemini config file: {fallback_config_path}")
                return config
            else:
                _log_warning(f"Gemini Banana config file not found: {config_path}")
                return {}
    except Exception as e:
        _log_error(f"Failed to load Gemini Banana config file: {e}")
        return {}

def get_gemini_banana_config():
    """Get Gemini Banana configuration, prioritize config file"""
    config = load_gemini_banana_config()
    return config

def process_input_image(image_tensor):
    """Process input image tensor and convert to PIL Image"""
    try:
        # Handle 4D tensor (batch)
        if image_tensor.dim() == 4:
            image_tensor = image_tensor[0]  # Take the first image
        
        # Convert CHW to HWC format
        if image_tensor.shape[0] in [1, 3, 4]:  # CHW format
            image_np = image_tensor.permute(1, 2, 0).cpu().numpy()
        else:  # Already HWC format
            image_np = image_tensor.cpu().numpy()
        
        # Normalize and convert to uint8
        if image_np.max() > 1.0:
            image_np = image_np / 255.0
        image_np = (image_np * 255).astype(np.uint8)
        
        # Handle channels
        if len(image_np.shape) == 3:
            if image_np.shape[2] == 1:
                image_np = np.repeat(image_np, 3, axis=2)  # Grayscale to RGB
            elif image_np.shape[2] == 4:
                image_np = image_np[:, :, :3]  # RGBA to RGB
        elif len(image_np.shape) == 2:
            image_np = np.stack([image_np] * 3, axis=2)  # Grayscale to RGB
        
        pil_image = Image.fromarray(image_np)
        
        # Resize if too large for API
        pil_image = resize_image_for_api(pil_image)
        
        return pil_image
    except Exception as e:
        _log_error(f"Failed to process input image: {e}")
        return None

def image_to_base64(image, format='JPEG', quality=95):
    """Convert PIL Image to base64 string"""
    try:
        buffer = io.BytesIO()
        
        # Handle alpha channel for JPEG
        if format.upper() == 'JPEG' and image.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', image.size, (255, 255, 255))
            if image.mode == 'P':
                image = image.convert('RGBA')
            if image.mode in ('RGBA', 'LA'):
                background.paste(image, mask=image.split()[-1])
                image = background
        
        image.save(buffer, format=format, quality=quality)
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    except Exception as e:
        _log_error(f"Failed to convert image to base64: {e}")
        return None

def process_generated_image_from_response(response_json):
    """ä»REST APIå“åº”ä¸­æå–ç”Ÿæˆçš„å›¾åƒ"""
    try:
        if "candidates" not in response_json:
            _log_warning("å“åº”ä¸­æœªæ‰¾åˆ°candidates")
            return create_dummy_image()
        
        for candidate in response_json["candidates"]:
            if "content" not in candidate or "parts" not in candidate["content"]:
                continue
                
            for part in candidate["content"]["parts"]:
                # æ£€æŸ¥inline_dataå­—æ®µï¼ˆå›¾åƒæ•°æ®ï¼‰
                inline_data = part.get("inline_data") or part.get("inlineData")
                if inline_data and "data" in inline_data:
                    try:
                        # è§£ç å›¾ç‰‡æ•°æ®
                        image_data = inline_data["data"]
                        image_bytes = base64.b64decode(image_data)
                        pil_image = Image.open(io.BytesIO(image_bytes))
                        
                        # ç¡®ä¿RGBæ ¼å¼
                        if pil_image.mode != 'RGB':
                            pil_image = pil_image.convert('RGB')
                        
                        # è½¬æ¢ä¸ºComfyUI tensoræ ¼å¼
                        img_array = np.array(pil_image)
                        img_tensor = torch.from_numpy(img_array).float() / 255.0
                        if len(img_tensor.shape) == 3:
                            img_tensor = img_tensor.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
                        
                        _log_info("âœ… æˆåŠŸæå–ç”Ÿæˆçš„å›¾åƒ")
                        return img_tensor
                    except Exception as e:
                        _log_error(f"è§£ç å›¾ç‰‡å¤±è´¥: {e}")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å›¾åƒï¼Œè¿”å›å ä½ç¬¦
        _log_warning("æœªæ£€æµ‹åˆ°ç”Ÿæˆçš„å›¾åƒï¼Œåˆ›å»ºå ä½ç¬¦")
        return create_dummy_image()
        
    except Exception as e:
        _log_error(f"å¤„ç†å“åº”å¤±è´¥: {e}")
        return create_dummy_image()

def extract_text_from_response(response_json):
    """ä»REST APIå“åº”ä¸­æå–æ–‡æœ¬"""
    try:
        response_text = ""
        
        if "candidates" not in response_json:
            return "No valid response received"
        
        for candidate in response_json["candidates"]:
            if "content" not in candidate or "parts" not in candidate["content"]:
                continue
                
            for part in candidate["content"]["parts"]:
                if "text" in part:
                    response_text += part["text"] + "\n"
        
        return response_text.strip() if response_text.strip() else "Response received but no text content"
        
    except Exception as e:
        _log_error(f"æå–æ–‡æœ¬å¤±è´¥: {e}")
        return "Failed to extract text from response"

def create_dummy_image(width=512, height=512):
    """Create a placeholder image"""
    dummy_array = np.zeros((height, width, 3), dtype=np.uint8)
    dummy_tensor = torch.from_numpy(dummy_array).float() / 255.0
    return dummy_tensor.unsqueeze(0)

def prepare_media_content(image=None, audio=None):
    """Prepare multimedia content for API calls"""
    content_parts = []
    
    if image is not None:
        pil_image = process_input_image(image)
        if pil_image:
            img_base64 = image_to_base64(pil_image, format='PNG')
            if img_base64:
                content_parts.append({
                    "inline_data": {
                        "mime_type": "image/png",
                        "data": img_base64
                    }
                })
    
    if audio is not None:
        # Process audio data
        try:
            if isinstance(audio, torch.Tensor):
                audio_np = audio.cpu().numpy()
            else:
                audio_np = np.array(audio)
            
            # Create temporary WAV file
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                # Assume sample rate of 16000
                sample_rate = 16000
                with wave.open(temp_file.name, 'wb') as wav_file:
                    wav_file.setnchannels(1)  # Mono
                    wav_file.setsampwidth(2)  # 16-bit
                    wav_file.setframerate(sample_rate)
                    wav_file.writeframes((audio_np * 32767).astype(np.int16).tobytes())
                
                # Read audio file and encode
                with open(temp_file.name, 'rb') as f:
                    audio_data = base64.b64encode(f.read()).decode()
                
                content_parts.append({
                    "inline_data": {
                        "mime_type": "audio/wav",
                        "data": audio_data
                    }
                })
                
                # Clean up temporary file
                os.unlink(temp_file.name)
                
        except Exception as e:
            _log_error(f"Failed to process audio data: {e}")
    
    return content_parts

def generate_with_rest_api(api_key, model, content_parts, generation_config, max_retries=5, proxy=None, base_url=None):
    """ä½¿ç”¨REST APIçš„æ™ºèƒ½é‡è¯•æœºåˆ¶è°ƒç”¨"""
    
    # æ„å»ºAPI URL - æ”¯æŒé•œåƒç«™
    if base_url and base_url.strip():
        # ç§»é™¤æœ«å°¾çš„æ–œæ ï¼Œç¡®ä¿URLæ ¼å¼æ­£ç¡®
        base_url = base_url.rstrip('/')
        
        # å¦‚æœç”¨æˆ·æä¾›çš„æ˜¯å®Œæ•´URLï¼Œç›´æ¥ä½¿ç”¨
        if '/models/' in base_url and ':generateContent' in base_url:
            url = base_url
        # å¦‚æœæ˜¯åŸºç¡€URLï¼Œæ„å»ºå®Œæ•´è·¯å¾„
        elif base_url.endswith('/v1beta') or base_url.endswith('/v1'):
            url = f"{base_url}/models/{model}:generateContent"
        else:
            # é»˜è®¤æ·»åŠ v1betaè·¯å¾„
            url = f"{base_url}/v1beta/models/{model}:generateContent"
        
        _log_info(f"ğŸ”— ä½¿ç”¨é•œåƒç«™: {base_url}")
    else:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        _log_info(f"ğŸŒ ä½¿ç”¨å®˜æ–¹API: generativelanguage.googleapis.com")
    
    # æ„å»ºè¯·æ±‚æ•°æ®
    request_data = {
        "contents": [{
            "parts": content_parts
        }],
        "generationConfig": generation_config
    }
    
    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        "Content-Type": "application/json",
        "x-goog-api-key": api_key.strip()
    }
    
    # å¤„ç†ä»£ç†è®¾ç½®
    proxies = None
    if proxy and proxy.strip() and "None" not in proxy:
        proxies = {
            "http": proxy.strip(),
            "https": proxy.strip()
        }
        _log_info(f"ğŸ”Œ ä½¿ç”¨ä»£ç†: {proxy.strip()}")
    
    # è®¾ç½®åˆç†çš„è¶…æ—¶ï¼šè¿æ¥è¶…æ—¶10ç§’ï¼Œè¯»å–è¶…æ—¶60ç§’
    timeout = (10, 60)  # (connect_timeout, read_timeout)
    
    for attempt in range(max_retries):
        try:
            _log_info(f"ğŸŒ REST APIè°ƒç”¨ ({attempt + 1}/{max_retries}) æ¨¡å‹: {model}")
            
            # å‘é€è¯·æ±‚
            response = requests.post(url, headers=headers, json=request_data, timeout=timeout, proxies=proxies)
            
            # æˆåŠŸå“åº”
            if response.status_code == 200:
                return response.json()
            
            # å¤„ç†é”™è¯¯å“åº”
            else:
                _log_error(f"HTTPçŠ¶æ€ç : {response.status_code}")
                try:
                    error_detail = response.json()
                    _log_error(f"é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, indent=2, ensure_ascii=False)}")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é”™è¯¯
                    if response.status_code == 429:
                        error_message = error_detail.get("error", {}).get("message", "")
                        if "quota" in error_message.lower():
                            _log_warning("æ£€æµ‹åˆ°é…é¢é™åˆ¶é”™è¯¯")
                except:
                    _log_error(f"é”™è¯¯æ–‡æœ¬: {response.text}")
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼ŒæŠ›å‡ºå¼‚å¸¸
                if attempt == max_retries - 1:
                    response.raise_for_status()
                
                # æ™ºèƒ½ç­‰å¾…
                delay = smart_retry_delay(attempt, response.status_code)
                _log_info(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                time.sleep(delay)
                
        except requests.exceptions.RequestException as e:
            error_msg = str(e)
            _log_error(f"è¯·æ±‚å¤±è´¥: {error_msg}")
            if attempt == max_retries - 1:
                raise e
            else:
                delay = smart_retry_delay(attempt)
                _log_info(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                time.sleep(delay)
    
    raise Exception("æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")

class KenChenLLMGeminiBananaTextToImageBananaNode:
    CATEGORY = "Ken-Chen/LLM Agent Assistant"
    RETURN_TYPES = ("STRING", "IMAGE")
    RETURN_NAMES = ("generation_text", "generated_image")
    FUNCTION = "generate_image"
    

    
    @classmethod
    def INPUT_TYPES(s):
        config = get_gemini_banana_config()
        default_params = config.get('default_params', {})
        image_settings = config.get('image_settings', {})
        
        # Get image generation models from config, with fallback to core Banana models
        models = config.get('models', {}).get('image_gen_models', [])
        if not models:
            # Fallback to core Banana models if config is empty
            models = [
                "gemini-2.5-flash-image-preview",  # Latest Banana model
                "gemini-2.0-flash-preview-image-generation"
            ]
        
        # Get default model from config, prioritize latest Banana model
        default_model = config.get('default_model', {}).get('image_gen', "gemini-2.5-flash-image-preview")
        default_proxy = config.get('proxy', "http://127.0.0.1:None")
        
        # Get image control presets
        size_presets = image_settings.get('size_presets', ["512x512", "768x768", "1024x1024", "1024x1792", "1792x1024"])
        quality_presets = image_settings.get('quality_presets', ["standard", "hd"])
        style_presets = image_settings.get('style_presets', ["vivid", "natural"])
        if "None" not in style_presets:
            style_presets = ["None"] + style_presets
        
        return {
            "required": {
                "api_key": ("STRING", {
                    "default": "", 
                    "multiline": False,
                    "placeholder": "APIå¯†é’¥ï¼ˆç•™ç©ºæ—¶è‡ªåŠ¨ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰"
                }),
                "prompt": ("STRING", {"default": "A beautiful landscape with mountains and lake", "multiline": True}),
                "model": (
                    models,
                    {"default": default_model},
                ),
                "proxy": ("STRING", {"default": default_proxy, "multiline": False}),
                "size": (size_presets, {"default": image_settings.get('default_size', "1024x1024")}),
                "quality": (quality_presets, {"default": image_settings.get('default_quality', "hd")}),
                "style": (style_presets, {"default": image_settings.get('default_style', "natural")}),
                "temperature": ("FLOAT", {"default": default_params.get('temperature', 0.9), "min": 0.0, "max": 1.5}),
                "top_p": ("FLOAT", {"default": default_params.get('top_p', 0.9), "min": 0.0, "max": 1.0}),
                "top_k": ("INT", {"default": default_params.get('top_k', 40), "min": 0, "max": 100}),
                "max_output_tokens": ("INT", {"default": default_params.get('max_output_tokens', 2048), "min": 0, "max": 32768}),
                "seed": ("INT", {"default": default_params.get('seed', 0), "min": 0, "max": 0xfffffff}),
            },
            "optional": {
                "custom_size": ("STRING", {
                    "default": "", 
                    "multiline": False,
                    "placeholder": "è‡ªå®šä¹‰å°ºå¯¸ (å¦‚: 1920x1080)"
                }),
            },
            "hidden": {
                "unique_id": "UNIQUE_ID"
            }
        }
    


    def _push_chat(self, user_prompt: str, response_text: str, unique_id: str):
        if not PromptServer or not unique_id:
            return
        try:
            # é™åˆ¶æç¤ºè¯é•¿åº¦ï¼Œé¿å…è¿‡é•¿æ–‡æœ¬å¯¼è‡´æ˜¾ç¤ºé—®é¢˜
            max_prompt_length = 500
            max_response_length = 1000
            
            # æˆªæ–­è¿‡é•¿çš„æç¤ºè¯å’Œå“åº”
            display_prompt = user_prompt[:max_prompt_length] + ("..." if len(user_prompt) > max_prompt_length else "")
            display_response = response_text[:max_response_length] + ("..." if len(response_text) > max_response_length else "")
            
            render_spec = {
                "node_id": unique_id,
                "component": "ChatHistoryWidget",
                "props": {
                    "history": json.dumps([
                        {
                            "prompt": display_prompt,
                            "response": display_response,
                            "response_id": str(random.randint(100000, 999999)),
                            "timestamp": time.time(),
                        }
                    ], ensure_ascii=False)
                },
            }
            PromptServer.instance.send_sync("display_component", render_spec)
        except Exception as e:
            print(f"[LLM Agent Assistant] Chat push failed: {e}")
            pass

    def generate_image(
        self,
        api_key,
        prompt,
        model,
        proxy,
        size,
        quality,
        style,
        temperature,
        top_p,
        top_k,
        max_output_tokens,
        seed,
        custom_size: str = "",
        unique_id: str = "",
    ):
        try:
            # å¦‚æœç”¨æˆ·æ²¡æœ‰è¾“å…¥APIå¯†é’¥ï¼Œè‡ªåŠ¨ä»é…ç½®æ–‡ä»¶è·å–
            if not api_key or not api_key.strip():
                config = get_gemini_banana_config()
                auto_api_key = config.get('api_key', '')
                if auto_api_key and auto_api_key.strip():
                    api_key = auto_api_key.strip()
                    _log_info(f"ğŸ”‘ è‡ªåŠ¨ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥: {api_key[:8]}...")
                else:
                    error_msg = "APIå¯†é’¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®api_keyæˆ–æ‰‹åŠ¨è¾“å…¥"
                    _log_error(error_msg)
                    return (error_msg, create_dummy_image())
            
            # éªŒè¯æç¤ºè¯
            if not prompt.strip():
                error_msg = "æç¤ºè¯ä¸èƒ½ä¸ºç©º"
                _log_error(error_msg)
                return (error_msg, create_dummy_image())
            
            # å¤„ç†å›¾åƒæ§åˆ¶å‚æ•°
            controls = process_image_controls(size, quality, style, custom_size)
            enhanced_prompt = enhance_prompt_with_controls(prompt.strip(), controls)
            
            _log_info(f"ğŸ¨ å›¾åƒæ§åˆ¶å‚æ•°: å°ºå¯¸={controls['size']}, è´¨é‡={controls['quality']}, é£æ ¼={controls['style']}")
            if controls['is_custom_size']:
                _log_info(f"ğŸ“ ä½¿ç”¨è‡ªå®šä¹‰å°ºå¯¸: {controls['size']}")
            
            # ä»£ç†å¤„ç†ï¼šä½¿ç”¨ proxies å‚æ•°ï¼Œä¸è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé¿å…å†²çª
            if proxy and proxy.strip() and "None" not in proxy:
                # ä½¿ç”¨ proxies å‚æ•°ï¼Œä¸è®¾ç½®ç¯å¢ƒå˜é‡
                _log_info(f"ä½¿ç”¨ä»£ç†: {proxy.strip()}")
            else:
                _log_info("æœªä½¿ç”¨ä»£ç†")
            
            # æ„å»ºç”Ÿæˆé…ç½®
            generation_config = {
                "temperature": temperature,
                "topP": top_p,
                "topK": top_k,
                "maxOutputTokens": max_output_tokens,
                "responseModalities": ["TEXT", "IMAGE"]  # å…³é”®ï¼šå¯ç”¨å›¾åƒç”Ÿæˆ
            }
            
            # æ™ºèƒ½ç§å­æ§åˆ¶
            if seed > 0:
                generation_config["seed"] = seed
            
            # å‡†å¤‡å†…å®¹
            content_parts = [{"text": enhanced_prompt}]
            
            # ä½¿ç”¨REST APIè°ƒç”¨
            _log_info(f"ğŸ¨ ä½¿ç”¨æ¨¡å‹ {model} ç”Ÿæˆå›¾åƒ...")
            _log_info(f"ğŸ“ æç¤ºè¯: {enhanced_prompt[:100]}...")
            
            response_json = generate_with_rest_api(api_key, model, content_parts, generation_config, proxy=proxy, base_url=None)
            
            # å¤„ç†å“åº”
            raw_text = extract_text_from_response(response_json)
            generated_image = process_generated_image_from_response(response_json)
            
            # å¼ºåˆ¶è°ƒæ•´å›¾åƒå°ºå¯¸åˆ°ç”¨æˆ·æŒ‡å®šçš„å°ºå¯¸
            if generated_image is not None:
                try:
                    target_width, target_height = map(int, controls['size'].split('x'))
                    current_width, current_height = generated_image.size
                    
                    if (current_width, current_height) != (target_width, target_height):
                        _log_info(f"ğŸ”„ å¼ºåˆ¶è°ƒæ•´å›¾åƒå°ºå¯¸: {current_width}x{current_height} -> {target_width}x{target_height}")
                        
                        # å¦‚æœç›®æ ‡å°ºå¯¸æ¯”ä¾‹ä¸åŒï¼Œä½¿ç”¨æ™ºèƒ½å¡«å……æ–¹æ³•
                        if current_width/current_height != target_width/target_height:
                            _log_info(f"ğŸ“ æ£€æµ‹åˆ°æ¯”ä¾‹å˜åŒ–ï¼Œä½¿ç”¨æ™ºèƒ½å¡«å……æ–¹æ³•")
                            
                            # æ–¹æ³•1: æ‹‰ä¼¸å¡«å……ï¼ˆä¿æŒå®½é«˜æ¯”ï¼Œå¯èƒ½è£å‰ªéƒ¨åˆ†å†…å®¹ï¼‰
                            # è®¡ç®—å¡«å……æ¯”ä¾‹ï¼Œç¡®ä¿è¦†ç›–æ•´ä¸ªç›®æ ‡åŒºåŸŸ
                            scale_x = target_width / current_width
                            scale_y = target_height / current_height
                            scale = max(scale_x, scale_y)  # ä½¿ç”¨è¾ƒå¤§çš„ç¼©æ”¾æ¯”ä¾‹
                            
                            new_width = int(current_width * scale)
                            new_height = int(current_height * scale)
                            
                            # ç¼©æ”¾å›¾åƒ
                            scaled_image = generated_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
                            
                            # åˆ›å»ºç›®æ ‡å°ºå¯¸çš„ç”»å¸ƒ
                            new_image = Image.new('RGB', (target_width, target_height), (255, 255, 255))
                            
                            # è®¡ç®—å±…ä¸­ä½ç½®
                            paste_x = (target_width - new_width) // 2
                            paste_y = (target_height - new_height) // 2
                            
                            # ç²˜è´´åˆ°æ–°ç”»å¸ƒä¸­å¿ƒ
                            new_image.paste(scaled_image, (paste_x, paste_y))
                            
                            # å¦‚æœå›¾åƒæ²¡æœ‰å®Œå…¨è¦†ç›–ç”»å¸ƒï¼Œä½¿ç”¨è¾¹ç¼˜æ‰©å±•
                            if paste_x < 0 or paste_y < 0:
                                _log_info(f"ğŸ”§ ä½¿ç”¨è¾¹ç¼˜æ‰©å±•å¡«å……ç©ºç™½åŒºåŸŸ")
                                # åˆ›å»ºæ›´å¤§çš„ä¸´æ—¶ç”»å¸ƒ
                                temp_width = max(target_width, new_width)
                                temp_height = max(target_height, new_height)
                                temp_image = Image.new('RGB', (temp_width, temp_height), (255, 255, 255))
                                
                                # å°†ç¼©æ”¾åçš„å›¾åƒå±…ä¸­æ”¾ç½®
                                temp_paste_x = (temp_width - new_width) // 2
                                temp_paste_y = (temp_height - new_height) // 2
                                temp_image.paste(scaled_image, (temp_paste_x, temp_paste_y))
                                
                                # è£å‰ªåˆ°ç›®æ ‡å°ºå¯¸
                                crop_x = (temp_width - target_width) // 2
                                crop_y = (temp_height - target_height) // 2
                                new_image = temp_image.crop((crop_x, crop_y, crop_x + target_width, crop_y + target_height))
                            
                            resized_image = new_image
                        else:
                            # æ¯”ä¾‹ç›¸åŒï¼Œç›´æ¥è°ƒæ•´å°ºå¯¸
                            resized_image = generated_image.resize((target_width, target_height), Image.Resampling.LANCZOS)
                        
                        generated_image = resized_image
                        _log_info(f"âœ… å›¾åƒå°ºå¯¸è°ƒæ•´å®Œæˆ: {generated_image.size}")
                    else:
                        _log_info(f"âœ… å›¾åƒå°ºå¯¸å·²ç¬¦åˆè¦æ±‚: {generated_image.size}")
                        
                except Exception as e:
                    _log_warning(f"å°ºå¯¸è°ƒæ•´å¤±è´¥: {e}, ä¿æŒåŸå§‹å°ºå¯¸")
            
            if not raw_text or raw_text == "Response received but no text content":
                assistant_text = "éµå‘½ï¼è¿™æ˜¯ä½ æ‰€è¦æ±‚çš„å›¾ç‰‡ï¼š"
            else:
                assistant_text = raw_text.strip()
            
            self._push_chat(enhanced_prompt, assistant_text, unique_id)
            
            _log_info("âœ… å›¾åƒç”ŸæˆæˆåŠŸå®Œæˆ")
            return (assistant_text, generated_image)
            
        except Exception as e:
            error_msg = str(e)
            _log_error(f"å›¾åƒç”Ÿæˆå¤±è´¥: {error_msg}")
            
            # å¢å¼ºçš„é”™è¯¯åˆ†ç±»å¤„ç†
            if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg or "quota" in error_msg.lower():
                friendly_error = (
                    "APIé…é¢è¶…é™ã€‚è§£å†³æ–¹æ¡ˆ:\n"
                    "1. ç­‰å¾…é…é¢é‡ç½®ï¼ˆé€šå¸¸24å°æ—¶ï¼‰\n"
                    "2. å‡çº§åˆ°ä»˜è´¹è´¦æˆ·\n" 
                    "3. ä½¿ç”¨å…è´¹æ¨¡å‹\n"
                    "4. æ£€æŸ¥è®¡è´¹è®¾ç½®"
                )
            elif "connection" in error_msg.lower() or "network" in error_msg.lower():
                friendly_error = f"ç½‘ç»œè¿æ¥é”™è¯¯: è¯·æ£€æŸ¥ä»£ç†è®¾ç½®å’Œç½‘ç»œè¿æ¥"
            elif "not found" in error_msg.lower() or "404" in error_msg:
                friendly_error = f"æ¨¡å‹ä¸å¯ç”¨: {model} å¯èƒ½ä¸æ”¯æŒå›¾åƒç”Ÿæˆæˆ–æš‚æ—¶ä¸å¯ç”¨"
            elif "API key" in error_msg or "401" in error_msg or "403" in error_msg:
                friendly_error = "APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"
            elif "safety" in error_msg.lower() or "blocked" in error_msg.lower():
                friendly_error = "å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢ï¼Œè¯·ä¿®æ”¹æç¤ºè¯"
            else:
                friendly_error = f"ç”Ÿæˆå¤±è´¥: {error_msg}"
            
            return (friendly_error, create_dummy_image())

class KenChenLLMGeminiBananaImageToImageBananaNode:
    CATEGORY = "Ken-Chen/LLM Agent Assistant"
    RETURN_TYPES = ("STRING", "IMAGE")
    RETURN_NAMES = ("generation_text", "generated_image")
    FUNCTION = "transform_image"
    

    
    @classmethod
    def INPUT_TYPES(s):
        config = get_gemini_banana_config()
        default_params = config.get('default_params', {})
        image_settings = config.get('image_settings', {})
        
        # Get image generation models from config, with fallback to core Banana models
        models = config.get('models', {}).get('image_gen_models', [])
        if not models:
            # Fallback to core Banana models if config is empty
            models = [
                "gemini-2.5-flash-image-preview",  # Latest Banana model
                "gemini-2.0-flash-preview-image-generation"
            ]
        
        # Get default model from config, prioritize latest Banana model
        default_model = config.get('default_model', {}).get('image_gen', "gemini-2.5-flash-image-preview")
        default_proxy = config.get('proxy', "http://127.0.0.1:None")
        
        # Get image control presets
        size_presets = image_settings.get('size_presets', ["512x512", "768x768", "1024x1024", "1024x1792", "1792x1024"])
        quality_presets = image_settings.get('quality_presets', ["standard", "hd"])
        style_presets = image_settings.get('style_presets', ["vivid", "natural"])
        if "None" not in style_presets:
            style_presets = ["None"] + style_presets
        
        return {
            "required": {
                "api_key": ("STRING", {
                    "default": "", 
                    "multiline": False,
                    "placeholder": "APIå¯†é’¥ï¼ˆç•™ç©ºæ—¶è‡ªåŠ¨ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰"
                }),
                "prompt": ("STRING", {"default": "Transform this image", "multiline": True}),
                "image": ("IMAGE",),
                "model": (
                    models,
                    {"default": default_model},
                ),
                "proxy": ("STRING", {"default": default_proxy, "multiline": False}),
                "size": (size_presets, {"default": image_settings.get('default_size', "1024x1024")}),
                "quality": (quality_presets, {"default": image_settings.get('default_quality', "hd")}),
                "style": (style_presets, {"default": image_settings.get('default_style', "natural")}),
                "temperature": ("FLOAT", {"default": default_params.get('temperature', 0.9), "min": 0.0, "max": 1.5}),
                "top_p": ("FLOAT", {"default": default_params.get('top_p', 0.9), "min": 0.0, "max": 1.0}),
                "top_k": ("INT", {"default": default_params.get('top_k', 40), "min": 0, "max": 100}),
                "max_output_tokens": ("INT", {"default": default_params.get('max_output_tokens', 2048), "min": 0, "max": 32768}),
                "seed": ("INT", {"default": default_params.get('seed', 0), "min": 0, "max": 0xfffffff}),
            },
            "optional": {
                "custom_size": ("STRING", {
                    "default": "", 
                    "multiline": False,
                    "placeholder": "è‡ªå®šä¹‰å°ºå¯¸ (å¦‚: 1920x1080)"
                }),
            },
            "hidden": {
                "unique_id": "UNIQUE_ID"
            }
        }
    
    RETURN_TYPES = ("STRING", "IMAGE")
    RETURN_NAMES = ("generation_text", "generated_image")
    FUNCTION = "transform_image"
    CATEGORY = "Ken-Chen/LLM Agent Assistant"

    def transform_image(
        self,
        api_key,
        prompt,
        image,
        model,
        proxy,
        size,
        quality,
        style,
        temperature,
        top_p,
        top_k,
        max_output_tokens,
        seed,
        custom_size: str = "",
        unique_id: str = "",
    ):
        try:
            # å¦‚æœç”¨æˆ·æ²¡æœ‰è¾“å…¥APIå¯†é’¥ï¼Œè‡ªåŠ¨ä»é…ç½®æ–‡ä»¶è·å–
            if not api_key or not api_key.strip():
                config = get_gemini_banana_config()
                auto_api_key = config.get('api_key', '')
                if auto_api_key and auto_api_key.strip():
                    api_key = auto_api_key.strip()
                    _log_info(f"ğŸ”‘ è‡ªåŠ¨ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥: {api_key[:8]}...")
                else:
                    error_msg = "APIå¯†é’¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®api_keyæˆ–æ‰‹åŠ¨è¾“å…¥"
                    _log_error(error_msg)
                    return (error_msg, create_dummy_image())
            
            # éªŒè¯æç¤ºè¯
            if not prompt.strip():
                error_msg = "æç¤ºè¯ä¸èƒ½ä¸ºç©º"
                _log_error(error_msg)
                return (error_msg, create_dummy_image())
            
            # å¤„ç†å›¾åƒæ§åˆ¶å‚æ•°
            controls = process_image_controls(size, quality, style, custom_size)
            enhanced_prompt = enhance_prompt_with_controls(prompt.strip(), controls)
            
            _log_info(f"ğŸ¨ å›¾åƒæ§åˆ¶å‚æ•°: å°ºå¯¸={controls['size']}, è´¨é‡={controls['quality']}, é£æ ¼={controls['style']}")
            if controls['is_custom_size']:
                _log_info(f"ğŸ“ ä½¿ç”¨è‡ªå®šä¹‰å°ºå¯¸: {controls['size']}")
            
            # ä»£ç†å¤„ç†ï¼šä½¿ç”¨ proxies å‚æ•°ï¼Œä¸è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé¿å…å†²çª
            if proxy and proxy.strip() and "None" not in proxy:
                # ä½¿ç”¨ proxies å‚æ•°ï¼Œä¸è®¾ç½®ç¯å¢ƒå˜é‡
                _log_info(f"ä½¿ç”¨ä»£ç†: {proxy.strip()}")
            else:
                _log_info("æœªä½¿ç”¨ä»£ç†")
            
            # æ„å»ºç”Ÿæˆé…ç½®
            generation_config = {
                "temperature": temperature,
                "topP": top_p,
                "topK": top_k,
                "maxOutputTokens": max_output_tokens,
                "responseModalities": ["TEXT", "IMAGE"]  # å…³é”®ï¼šå¯ç”¨å›¾åƒç”Ÿæˆ
            }
            
            # æ™ºèƒ½ç§å­æ§åˆ¶
            if seed > 0:
                generation_config["seed"] = seed
            
            # å‡†å¤‡å†…å®¹ - æ–‡æœ¬ + å›¾åƒ
            content_parts = [{"text": enhanced_prompt}]
            content_parts.extend(prepare_media_content(image=image))
            
            # ä½¿ç”¨REST APIè°ƒç”¨
            _log_info(f"ğŸ–¼ï¸ ä½¿ç”¨æ¨¡å‹ {model} è¿›è¡Œå›¾åƒè½¬æ¢...")
            _log_info(f"ğŸ“ è½¬æ¢æŒ‡ä»¤: {enhanced_prompt[:100]}...")
            
            response_json = generate_with_rest_api(api_key, model, content_parts, generation_config, proxy=proxy, base_url=None)
            
            # å¤„ç†å“åº”
            raw_text = extract_text_from_response(response_json)
            generated_image = process_generated_image_from_response(response_json)
            
            # å¼ºåˆ¶è°ƒæ•´å›¾åƒå°ºå¯¸åˆ°ç”¨æˆ·æŒ‡å®šçš„å°ºå¯¸
            if generated_image is not None:
                try:
                    target_width, target_height = map(int, controls['size'].split('x'))
                    current_width, current_height = generated_image.size
                    
                    if (current_width, current_height) != (target_width, target_height):
                        _log_info(f"ğŸ”„ å¼ºåˆ¶è°ƒæ•´å›¾åƒå°ºå¯¸: {current_width}x{current_height} -> {target_width}x{target_height}")
                        
                        # å¦‚æœç›®æ ‡å°ºå¯¸æ¯”ä¾‹ä¸åŒï¼Œä½¿ç”¨æ™ºèƒ½å¡«å……æ–¹æ³•
                        if current_width/current_height != target_width/target_height:
                            _log_info(f"ğŸ“ æ£€æµ‹åˆ°æ¯”ä¾‹å˜åŒ–ï¼Œä½¿ç”¨æ™ºèƒ½å¡«å……æ–¹æ³•")
                            
                            # æ–¹æ³•1: æ‹‰ä¼¸å¡«å……ï¼ˆä¿æŒå®½é«˜æ¯”ï¼Œå¯èƒ½è£å‰ªéƒ¨åˆ†å†…å®¹ï¼‰
                            # è®¡ç®—å¡«å……æ¯”ä¾‹ï¼Œç¡®ä¿è¦†ç›–æ•´ä¸ªç›®æ ‡åŒºåŸŸ
                            scale_x = target_width / current_width
                            scale_y = target_height / current_height
                            scale = max(scale_x, scale_y)  # ä½¿ç”¨è¾ƒå¤§çš„ç¼©æ”¾æ¯”ä¾‹
                            
                            new_width = int(current_width * scale)
                            new_height = int(current_height * scale)
                            
                            # ç¼©æ”¾å›¾åƒ
                            scaled_image = generated_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
                            
                            # åˆ›å»ºç›®æ ‡å°ºå¯¸çš„ç”»å¸ƒ
                            new_image = Image.new('RGB', (target_width, target_height), (255, 255, 255))
                            
                            # è®¡ç®—å±…ä¸­ä½ç½®
                            paste_x = (target_width - new_width) // 2
                            paste_y = (target_height - new_height) // 2
                            
                            # ç²˜è´´åˆ°æ–°ç”»å¸ƒä¸­å¿ƒ
                            new_image.paste(scaled_image, (paste_x, paste_y))
                            
                            # å¦‚æœå›¾åƒæ²¡æœ‰å®Œå…¨è¦†ç›–ç”»å¸ƒï¼Œä½¿ç”¨è¾¹ç¼˜æ‰©å±•
                            if paste_x < 0 or paste_y < 0:
                                _log_info(f"ğŸ”§ ä½¿ç”¨è¾¹ç¼˜æ‰©å±•å¡«å……ç©ºç™½åŒºåŸŸ")
                                # åˆ›å»ºæ›´å¤§çš„ä¸´æ—¶ç”»å¸ƒ
                                temp_width = max(target_width, new_width)
                                temp_height = max(target_height, new_height)
                                temp_image = Image.new('RGB', (temp_width, temp_height), (255, 255, 255))
                                
                                # å°†ç¼©æ”¾åçš„å›¾åƒå±…ä¸­æ”¾ç½®
                                temp_paste_x = (temp_width - new_width) // 2
                                temp_paste_y = (temp_height - new_height) // 2
                                temp_image.paste(scaled_image, (temp_paste_x, temp_paste_y))
                                
                                # è£å‰ªåˆ°ç›®æ ‡å°ºå¯¸
                                crop_x = (temp_width - target_width) // 2
                                crop_y = (temp_height - target_height) // 2
                                new_image = temp_image.crop((crop_x, crop_y, crop_x + target_width, crop_y + target_height))
                            
                            resized_image = new_image
                        else:
                            # æ¯”ä¾‹ç›¸åŒï¼Œç›´æ¥è°ƒæ•´å°ºå¯¸
                            resized_image = generated_image.resize((target_width, target_height), Image.Resampling.LANCZOS)
                        
                        generated_image = resized_image
                        _log_info(f"âœ… å›¾åƒå°ºå¯¸è°ƒæ•´å®Œæˆ: {generated_image.size}")
                    else:
                        _log_info(f"âœ… å›¾åƒå°ºå¯¸å·²ç¬¦åˆè¦æ±‚: {generated_image.size}")
                        
                except Exception as e:
                    _log_warning(f"å°ºå¯¸è°ƒæ•´å¤±è´¥: {e}, ä¿æŒåŸå§‹å°ºå¯¸")
            
            # å¦‚æœæ²¡æœ‰ç”Ÿæˆæ–°å›¾åƒï¼Œè¿”å›åŸå›¾åƒ
            if generated_image is None:
                _log_warning("æœªæ£€æµ‹åˆ°ç¼–è¾‘åçš„å›¾åƒï¼Œè¿”å›åŸå›¾åƒ")
                generated_image = image if image is not None else create_dummy_image()
            
            if not raw_text or raw_text == "Response received but no text content":
                assistant_text = "éµå‘½ï¼è¿™æ˜¯æ ¹æ®ä½ çš„ç¼–è¾‘æŒ‡ä»¤ç”Ÿæˆçš„å›¾ç‰‡ï¼š"
            else:
                assistant_text = raw_text.strip()
            
            self._push_chat(enhanced_prompt, assistant_text, unique_id)
            
            _log_info("âœ… å›¾åƒè½¬æ¢æˆåŠŸå®Œæˆ")
            return (assistant_text, generated_image)
            
        except Exception as e:
            error_msg = str(e)
            _log_error(f"å›¾åƒè½¬æ¢å¤±è´¥: {error_msg}")
            
            # å¢å¼ºçš„é”™è¯¯åˆ†ç±»å¤„ç†
            if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg or "quota" in error_msg.lower():
                friendly_error = (
                    "APIé…é¢è¶…é™ã€‚è§£å†³æ–¹æ¡ˆ:\n"
                    "1. ç­‰å¾…é…é¢é‡ç½®ï¼ˆé€šå¸¸24å°æ—¶ï¼‰\n"
                    "2. å‡çº§åˆ°ä»˜è´¹è´¦æˆ·\n"
                    "3. ä½¿ç”¨å…è´¹æ¨¡å‹\n"
                    "4. æ£€æŸ¥è®¡è´¹è®¾ç½®"
                )
            elif "connection" in error_msg.lower() or "network" in error_msg.lower():
                friendly_error = f"ç½‘ç»œè¿æ¥é”™è¯¯: è¯·æ£€æŸ¥ä»£ç†è®¾ç½®å’Œç½‘ç»œè¿æ¥"
            elif "not found" in error_msg.lower() or "404" in error_msg:
                friendly_error = f"æ¨¡å‹ä¸å¯ç”¨: {model} å¯èƒ½ä¸æ”¯æŒå›¾åƒè½¬æ¢æˆ–æš‚æ—¶ä¸å¯ç”¨"
            elif "API key" in error_msg or "401" in error_msg or "403" in error_msg:
                friendly_error = "APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"
            elif "safety" in error_msg.lower() or "blocked" in error_msg.lower():
                friendly_error = "å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢ï¼Œè¯·ä¿®æ”¹æç¤ºè¯æˆ–å›¾åƒ"
            else:
                friendly_error = f"è½¬æ¢å¤±è´¥: {error_msg}"
            
            return (friendly_error, image if image is not None else create_dummy_image())

class KenChenLLMGeminiBananaMultimodalBananaNode:
    CATEGORY = "Ken-Chen/LLM Agent Assistant"
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("text",)
    FUNCTION = "analyze_multimodal"
    

    
    @classmethod
    def INPUT_TYPES(s):
        config = get_gemini_banana_config()
        default_params = config.get('default_params', {})
        
        # Get multimodal models from config, with fallback to latest models
        models = config.get('models', {}).get('multimodal_models', [])
        if not models:
            # Fallback to latest models if config is empty - only include true multimodal models
            models = [
                "gemini-2.5-pro-exp-03-25",  # Latest multimodal model - supports image+text
                "gemini-2.5-flash-preview-04-17",  # Supports image+text
                "gemini-2.5-pro-preview-05-06",  # Supports image+text
                "gemini-2.0-flash-exp-image-generation",  # Supports image+text
            ]
        
        # Get default model from config, prioritize latest models
        default_model = config.get('default_model', {}).get('multimodal', "gemini-2.5-pro-exp-03-25")
        default_proxy = config.get('proxy', "http://127.0.0.1:None")
        
        return {
            "required": {
                "api_key": ("STRING", {
                    "default": get_gemini_banana_config().get('multimodal_api_key', ''), 
                    "multiline": False,
                    "placeholder": "APIå¯†é’¥ï¼ˆç•™ç©ºæ—¶è‡ªåŠ¨ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰"
                }),
                "prompt": ("STRING", {"default": "Describe what you see", "multiline": True}),
                "model": (
                    models,
                    {"default": default_model},
                ),

                "proxy": ("STRING", {"default": default_proxy, "multiline": False}),
                "temperature": ("FLOAT", {"default": default_params.get('temperature', 0.9), "min": 0.0, "max": 1.5}),
                "top_p": ("FLOAT", {"default": default_params.get('top_p', 0.9), "min": 0.0, "max": 1.0}),
                "top_k": ("INT", {"default": default_params.get('top_k', 40), "min": 0, "max": 100}),
                "max_output_tokens": ("INT", {"default": default_params.get('max_output_tokens', 2048), "min": 0, "max": 8192}),
                "seed": ("INT", {"default": default_params.get('seed', 0), "min": 0, "max": 0xfffffff}),
            },
            "optional": {
                "image": ("IMAGE",),
                "audio": ("AUDIO",),
            },
        }
    

    
    def analyze_multimodal(
        self,
        api_key,
        prompt,
        model,
        proxy,
        temperature,
        top_p,
        top_k,
        max_output_tokens,
        seed,
        image=None,
        audio=None,
    ):
        try:
            # å¦‚æœç”¨æˆ·æ²¡æœ‰è¾“å…¥APIå¯†é’¥ï¼Œè‡ªåŠ¨ä»é…ç½®æ–‡ä»¶è·å–
            if not api_key or not api_key.strip():
                config = get_gemini_banana_config()
                auto_api_key = config.get('multimodal_api_key', '')
                if auto_api_key and auto_api_key.strip():
                    api_key = auto_api_key.strip()
                    _log_info(f"ğŸ”‘ è‡ªåŠ¨ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥: {api_key[:8]}...")
                else:
                    error_msg = "APIå¯†é’¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®multimodal_api_keyæˆ–æ‰‹åŠ¨è¾“å…¥"
                    _log_error(error_msg)
                    return (error_msg,)
            
            # è®¾ç½®ä»£ç†
            # ä»£ç†å¤„ç†ï¼šä½¿ç”¨ proxies å‚æ•°ï¼Œä¸è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé¿å…å†²çª
            if proxy and proxy.strip() and "None" not in proxy:
                # ä½¿ç”¨ proxies å‚æ•°ï¼Œä¸è®¾ç½®ç¯å¢ƒå˜é‡
                _log_info(f"ä½¿ç”¨ä»£ç†: {proxy.strip()}")
            else:
                _log_info("æœªä½¿ç”¨ä»£ç†")
            
            # æ„å»ºç”Ÿæˆé…ç½®ï¼ˆå¤šæ¨¡æ€åˆ†æåªéœ€è¦TEXTè¾“å‡ºï¼‰
            generation_config = {
                "temperature": temperature,
                "topP": top_p,
                "topK": top_k,
                "maxOutputTokens": max_output_tokens,
                "responseModalities": ["TEXT"]  # åªéœ€è¦æ–‡æœ¬è¾“å‡º
            }
            
            if seed > 0:
                generation_config["seed"] = seed
            

            
            # å‡†å¤‡å†…å®¹ - æ–‡æœ¬ + å¤šåª’ä½“
            content_parts = [{"text": prompt.strip()}]
            content_parts.extend(prepare_media_content(image=image, audio=audio))
            
            # ä½¿ç”¨REST APIè°ƒç”¨
            _log_info(f"ğŸ” ä½¿ç”¨æ¨¡å‹ {model} è¿›è¡Œå¤šæ¨¡æ€åˆ†æ...")
            _log_info(f"ğŸ“ åˆ†ææç¤º: {prompt[:100]}...")
            
            response_json = generate_with_rest_api(api_key, model, content_parts, generation_config, proxy=proxy)
            
            # æå–æ–‡æœ¬å“åº”
            generated_text = extract_text_from_response(response_json)
            
            if not generated_text or generated_text == "Response received but no text content":
                generated_text = "æ¨¡å‹æœªè¿”å›æœ‰æ•ˆçš„åˆ†æç»“æœ"
            
            _log_info("âœ… å¤šæ¨¡æ€åˆ†ææˆåŠŸå®Œæˆ")
            return (generated_text,)
            
        except Exception as e:
            error_msg = str(e)
            _log_error(f"å¤šæ¨¡æ€åˆ†æå¤±è´¥: {error_msg}")
            
            # å¢å¼ºçš„é”™è¯¯åˆ†ç±»å¤„ç†
            if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg or "quota" in error_msg.lower():
                friendly_error = (
                    "APIé…é¢è¶…é™ã€‚è§£å†³æ–¹æ¡ˆ:\n"
                    "1. ç­‰å¾…é…é¢é‡ç½®ï¼ˆé€šå¸¸24å°æ—¶ï¼‰\n"
                    "2. å‡çº§åˆ°ä»˜è´¹è´¦æˆ·\n"
                    "3. ä½¿ç”¨å…è´¹æ¨¡å‹\n"
                    "4. æ£€æŸ¥è®¡è´¹è®¾ç½®"
                )
            elif "connection" in error_msg.lower() or "network" in error_msg.lower():
                friendly_error = f"ç½‘ç»œè¿æ¥é”™è¯¯: è¯·æ£€æŸ¥ä»£ç†è®¾ç½®å’Œç½‘ç»œè¿æ¥"
            elif "not found" in error_msg.lower() or "404" in error_msg:
                friendly_error = f"æ¨¡å‹ä¸å¯ç”¨: {model} å¯èƒ½ä¸æ”¯æŒå¤šæ¨¡æ€åˆ†ææˆ–æš‚æ—¶ä¸å¯ç”¨"
            elif "API key" in error_msg or "401" in error_msg or "403" in error_msg:
                friendly_error = "APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"
            elif "safety" in error_msg.lower() or "blocked" in error_msg.lower():
                friendly_error = "å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢ï¼Œè¯·ä¿®æ”¹æç¤ºè¯æˆ–åª’ä½“å†…å®¹"
            else:
                friendly_error = f"åˆ†æå¤±è´¥: {error_msg}"
            
            return (friendly_error,)

class KenChenLLMGeminiBananaMultiImageEditNode:
    """
    Gemini Banana å¤šå›¾åƒç¼–è¾‘èŠ‚ç‚¹
    
    åŠŸèƒ½ç‰¹æ€§:
    - æ”¯æŒå¤šå¼ è¾“å…¥å›¾åƒï¼ˆæœ€å¤š4å¼ ï¼‰
    - ä¸“ä¸šçš„å›¾åƒç¼–è¾‘æç¤ºè¯
    - æ”¯æŒå°ºå¯¸ã€è´¨é‡ã€é£æ ¼æ§åˆ¶
    - æ™ºèƒ½å›¾åƒç»„åˆç¼–è¾‘
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        from .gemini_banana import get_gemini_banana_config
        config = get_gemini_banana_config()
        default_params = config.get('default_params', {})
        image_settings = config.get('image_settings', {})
        
        # Get image control presets
        size_presets = image_settings.get('size_presets', ["512x512", "768x768", "1024x1024", "1024x1792", "1792x1024"])
        quality_presets = image_settings.get('quality_presets', ["standard", "hd"])
        style_presets = image_settings.get('style_presets', ["vivid", "natural"])
        
        return {
            "required": {
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "prompt": ("STRING", {"default": "è¯·æ ¹æ®è¿™äº›å›¾ç‰‡è¿›è¡Œä¸“ä¸šçš„å›¾åƒç¼–è¾‘", "multiline": True}),
                "model": (["gemini-2.5-flash-image-preview", "gemini-2.0-flash"], {"default": "gemini-2.5-flash-image-preview"}),
                "size": (size_presets, {"default": image_settings.get('default_size', "1024x1024")}),
                "quality": (quality_presets, {"default": image_settings.get('default_quality', "hd")}),
                "style": (style_presets, {"default": image_settings.get('default_style', "natural")}),
                "temperature": ("FLOAT", {"default": default_params.get('temperature', 0.9), "min": 0.0, "max": 1.5}),
                "top_p": ("FLOAT", {"default": default_params.get('top_p', 0.95), "min": 0.0, "max": 1.0}),
                "top_k": ("INT", {"default": default_params.get('top_k', 40), "min": 0, "max": 100}),
                "max_output_tokens": ("INT", {"default": default_params.get('max_output_tokens', 8192), "min": 0, "max": 32768}),
                "seed": ("INT", {"default": default_params.get('seed', 0), "min": 0, "max": 999999}),
            },
            "optional": {
                "custom_size": ("STRING", {
                    "default": "", 
                    "multiline": False,
                    "placeholder": "è‡ªå®šä¹‰å°ºå¯¸ (å¦‚: 1920x1080)"
                }),
                "image1": ("IMAGE",),
                "image2": ("IMAGE",),
                "image3": ("IMAGE",),
                "image4": ("IMAGE",),
            },
            "hidden": {
                "unique_id": "UNIQUE_ID"
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("edited_image", "response_text")
    FUNCTION = "edit_multiple_images"
    CATEGORY = "Ken-Chen/LLM Agent Assistant"

    def _push_chat(self, user_prompt: str, response_text: str, unique_id: str):
        if not PromptServer or not unique_id:
            return
        try:
            render_spec = {
                "node_id": unique_id,
                "component": "ChatHistoryWidget",
                "props": {
                    "history": json.dumps([
                        {
                            "prompt": user_prompt,
                            "response": response_text,
                            "response_id": str(random.randint(100000, 999999)),
                            "timestamp": time.time(),
                        }
                    ])
                },
            }
            PromptServer.instance.send_sync("display_component", render_spec)
        except Exception:
            pass

    def edit_multiple_images(self, api_key: str, prompt: str, model: str, size: str, quality: str, style: str,
                           temperature: float, top_p: float, top_k: int, max_output_tokens: int, seed: int,
                           custom_size: str = "", image1=None, image2=None, image3=None, image4=None,
                           unique_id: str = "") -> Tuple[torch.Tensor, str]:
        """ä½¿ç”¨ Gemini API è¿›è¡Œå¤šå›¾åƒç¼–è¾‘"""
        
        # éªŒè¯APIå¯†é’¥
        if not validate_api_key(api_key):
            raise ValueError("API Keyæ ¼å¼æ— æ•ˆæˆ–ä¸ºç©º")
        
        # éªŒè¯æç¤ºè¯
        if not prompt.strip():
            raise ValueError("æç¤ºè¯ä¸èƒ½ä¸ºç©º")
        
        # å¤„ç†å›¾åƒæ§åˆ¶å‚æ•°
        controls = process_image_controls(size, quality, style, custom_size)
        enhanced_prompt = enhance_prompt_with_controls(prompt.strip(), controls)
        
        print(f"ğŸ¨ å›¾åƒæ§åˆ¶å‚æ•°: å°ºå¯¸={controls['size']}, è´¨é‡={controls['quality']}, é£æ ¼={controls['style']}")
        if controls['is_custom_size']:
            print(f"ğŸ“ ä½¿ç”¨è‡ªå®šä¹‰å°ºå¯¸: {controls['size']}")
        
        # æ”¶é›†æ‰€æœ‰è¾“å…¥çš„å›¾åƒ
        all_input_pils = []
        input_images = [image1, image2, image3, image4]
        
        for i, img_tensor in enumerate(input_images):
            if img_tensor is not None:
                try:
                    pil_image = tensor_to_pil(img_tensor)
                    if pil_image:
                        all_input_pils.append(pil_image)
                        print(f"ğŸ“¸ æ·»åŠ è¾“å…¥å›¾åƒ {i+1}: {pil_image.size}")
                except Exception as e:
                    print(f"âš ï¸ å›¾åƒ {i+1} å¤„ç†å¤±è´¥: {e}")
        
        if not all_input_pils:
            raise ValueError("é”™è¯¯ï¼šè¯·è¾“å…¥è‡³å°‘ä¸€å¼ è¦ç¼–è¾‘çš„å›¾åƒ")
        
        print(f"ğŸ–¼ï¸ æ€»å…±æ”¶é›†åˆ° {len(all_input_pils)} å¼ è¾“å…¥å›¾åƒ")
        
        # æ™ºèƒ½ç”Ÿæˆå¤šå›¾ç¼–è¾‘æç¤ºè¯
        # é¦–å…ˆå¤„ç†å›¾ç‰‡å¼•ç”¨è½¬æ¢ï¼Œç¡®ä¿æ‰€æœ‰æƒ…å†µä¸‹éƒ½èƒ½ä½¿ç”¨
        user_intent = prompt.strip()
        converted_prompt = user_intent
        
        # è½¬æ¢æ‰€æœ‰å›¾ç‰‡å¼•ç”¨ - é€šç”¨åŒ–å¤„ç†
        if len(all_input_pils) >= 1:
            converted_prompt = converted_prompt.replace("å›¾1", "ç¬¬ä¸€å¼ å›¾ç‰‡")
        if len(all_input_pils) >= 2:
            converted_prompt = converted_prompt.replace("å›¾2", "ç¬¬äºŒå¼ å›¾ç‰‡")
        if len(all_input_pils) >= 3:
            converted_prompt = converted_prompt.replace("å›¾3", "ç¬¬ä¸‰å¼ å›¾ç‰‡")
        if len(all_input_pils) >= 4:
            converted_prompt = converted_prompt.replace("å›¾4", "ç¬¬å››å¼ å›¾ç‰‡")
        
        # æ ¹æ®å›¾ç‰‡æ•°é‡ç”Ÿæˆä¸åŒçš„æç¤ºè¯ - å®Œå…¨é€šç”¨åŒ–
        if len(all_input_pils) == 2:
            # 2å¼ å›¾ç‰‡ï¼šé€šç”¨ç»„åˆç¼–è¾‘
            full_prompt = f"""è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚è¿›è¡Œå›¾åƒç¼–è¾‘ï¼š

{converted_prompt}

é‡è¦è¯´æ˜ï¼š
- è¯·ä»”ç»†åˆ†æä¸¤å¼ å›¾ç‰‡çš„å†…å®¹å’Œå…³ç³»
- æ ¹æ®ç”¨æˆ·çš„å…·ä½“æŒ‡ä»¤ï¼Œå°†ç¬¬äºŒå¼ å›¾ç‰‡ä¸­çš„å…ƒç´ åº”ç”¨åˆ°ç¬¬ä¸€å¼ å›¾ç‰‡ä¸­
- ä¿æŒç¬¬ä¸€å¼ å›¾ç‰‡çš„æ ¸å¿ƒç‰¹å¾å’ŒèƒŒæ™¯ç¯å¢ƒ
- ç¡®ä¿ç¬¬äºŒå¼ å›¾ç‰‡ä¸­çš„å…ƒç´ ä¸ç¬¬ä¸€å¼ å›¾ç‰‡å®Œç¾èåˆ
- ç¼–è¾‘ç»“æœåº”è¯¥çœ‹èµ·æ¥è‡ªç„¶çœŸå®ï¼Œç¬¦åˆç”¨æˆ·æ„å›¾

{enhanced_prompt}

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚æ‰§è¡Œï¼Œç¡®ä¿ç¼–è¾‘ç»“æœå®Œå…¨ç¬¦åˆç”¨æˆ·æ„å›¾ã€‚"""
        elif len(all_input_pils) == 1:
            full_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒç¼–è¾‘ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ç¼–è¾‘è¿™å¼ å›¾ç‰‡ï¼š

{enhanced_prompt}

è¯·ä½¿ç”¨ä½ çš„å›¾åƒç¼–è¾‘èƒ½åŠ›ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ç¼–è¾‘ç»“æœã€‚"""
        else:
            full_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒç¼–è¾‘ä¸“å®¶ã€‚è¯·æ ¹æ®è¿™äº›å›¾ç‰‡å’Œä»¥ä¸‹æŒ‡ä»¤è¿›è¡Œå›¾åƒç¼–è¾‘ï¼š

{enhanced_prompt}

è¯·ä½¿ç”¨ä½ çš„å›¾åƒç¼–è¾‘èƒ½åŠ›ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ç¼–è¾‘ç»“æœã€‚ç¡®ä¿ç¼–è¾‘åçš„å›¾åƒç¬¦åˆæ‰€æœ‰è¦æ±‚ã€‚"""
        
        # æ„å»ºAPIè¯·æ±‚å†…å®¹
        content = [{"type": "text", "text": full_prompt}]
        
        # æ·»åŠ æ‰€æœ‰å›¾åƒä½œä¸ºå‚è€ƒ
        for i, pil_image in enumerate(all_input_pils):
            # è°ƒæ•´å›¾åƒå°ºå¯¸ä»¥ç¬¦åˆAPIè¦æ±‚
            pil_image = resize_image_for_api(pil_image)
            # è½¬æ¢ä¸ºbase64
            image_base64 = image_to_base64(pil_image, format='JPEG')
            content.append({
                "inline_data": {
                    "mime_type": "image/jpeg",
                    "data": image_base64
                }
            })
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        request_data = {
            "contents": [{
                "parts": content
            }],
            "generationConfig": {
                "temperature": temperature,
                "topP": top_p,
                "topK": top_k,
                "maxOutputTokens": max_output_tokens,
                "responseModalities": ["TEXT", "IMAGE"],
                "seed": seed if seed and seed > 0 else None
            }
        }
        
        # æ¸…ç† None å€¼
        if request_data["generationConfig"]["seed"] is None:
            del request_data["generationConfig"]["seed"]
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": api_key.strip()
        }
        
        # æ™ºèƒ½é‡è¯•æœºåˆ¶
        max_retries = 5
        timeout = 120
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ–¼ï¸ æ­£åœ¨ç¼–è¾‘å›¾ç‰‡... (å°è¯• {attempt + 1}/{max_retries})")
                print(f"ğŸ“ ç¼–è¾‘æŒ‡ä»¤: {enhanced_prompt[:100]}...")
                print(f"ğŸ”— ä½¿ç”¨æ¨¡å‹: {model}")
                
                # å‘é€è¯·æ±‚
                response = requests.post(
                    f"{get_gemini_banana_config().get('base_url', 'https://generativelanguage.googleapis.com')}/v1beta/models/{model}:generateContent",
                    headers=headers,
                    json=request_data,
                    timeout=timeout
                )
                
                # æˆåŠŸå“åº”
                if response.status_code == 200:
                    # è§£æå“åº”
                    result = response.json()
                    print(f"ğŸ“‹ APIå“åº”ç»“æ„: {list(result.keys())}")
                    
                    # æå–æ–‡æœ¬å“åº”å’Œç¼–è¾‘åçš„å›¾ç‰‡
                    response_text = ""
                    edited_image = None
                    
                    if "candidates" in result and result["candidates"]:
                        candidate = result["candidates"][0]
                        if "content" in candidate and "parts" in candidate["content"]:
                            for part in candidate["content"]["parts"]:
                                # æå–æ–‡æœ¬
                                if "text" in part:
                                    response_text += part["text"]
                                
                                # æå–ç¼–è¾‘åçš„å›¾ç‰‡
                                if "inline_data" in part or "inlineData" in part:
                                    inline_data = part.get("inline_data") or part.get("inlineData")
                                    if inline_data and "data" in inline_data:
                                        try:
                                            # è§£ç å›¾ç‰‡æ•°æ®
                                            image_data = inline_data["data"]
                                            image_bytes = base64.b64decode(image_data)
                                            edited_image = Image.open(io.BytesIO(image_bytes))
                                            print("âœ… æˆåŠŸæå–ç¼–è¾‘åçš„å›¾ç‰‡")
                                        except Exception as e:
                                            print(f"âš ï¸ è§£ç å›¾ç‰‡å¤±è´¥: {e}")
                    
                    # å¦‚æœæ²¡æœ‰ç¼–è¾‘åçš„å›¾ç‰‡ï¼Œè¿”å›åŸå›¾ç‰‡
                    if edited_image is None:
                        print("âš ï¸ æœªæ£€æµ‹åˆ°ç¼–è¾‘åçš„å›¾ç‰‡ï¼Œè¿”å›åŸå›¾ç‰‡")
                        edited_image = all_input_pils[0]  # è¿”å›ç¬¬ä¸€å¼ å›¾ç‰‡
                        if not response_text:
                            response_text = "å›¾ç‰‡ç¼–è¾‘è¯·æ±‚å·²å‘é€ï¼Œä½†æœªæ”¶åˆ°ç¼–è¾‘åçš„å›¾ç‰‡"
                    
                    # å¼ºåˆ¶è°ƒæ•´å›¾åƒå°ºå¯¸åˆ°ç”¨æˆ·æŒ‡å®šçš„å°ºå¯¸
                    try:
                        target_width, target_height = map(int, controls['size'].split('x'))
                        current_width, current_height = edited_image.size
                        
                        if (current_width, current_height) != (target_width, target_height):
                            print(f"ğŸ”„ å¼ºåˆ¶è°ƒæ•´å›¾åƒå°ºå¯¸: {current_width}x{current_height} -> {target_width}x{target_height}")
                            
                            # å¦‚æœç›®æ ‡å°ºå¯¸æ¯”ä¾‹ä¸åŒï¼Œä½¿ç”¨æ™ºèƒ½å¡«å……æ–¹æ³•
                            if current_width/current_height != target_width/target_height:
                                print(f"ğŸ“ æ£€æµ‹åˆ°æ¯”ä¾‹å˜åŒ–ï¼Œä½¿ç”¨æ™ºèƒ½å¡«å……æ–¹æ³•")
                                
                                # è®¡ç®—å¡«å……æ¯”ä¾‹ï¼Œç¡®ä¿è¦†ç›–æ•´ä¸ªç›®æ ‡åŒºåŸŸ
                                scale_x = target_width / current_width
                                scale_y = target_height / current_height
                                scale = max(scale_x, scale_y)  # ä½¿ç”¨è¾ƒå¤§çš„ç¼©æ”¾æ¯”ä¾‹
                                
                                new_width = int(current_width * scale)
                                new_height = int(current_height * scale)
                                
                                # ç¼©æ”¾å›¾åƒ
                                scaled_image = edited_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
                                
                                # åˆ›å»ºç›®æ ‡å°ºå¯¸çš„ç”»å¸ƒ
                                new_image = Image.new('RGB', (target_width, target_height), (255, 255, 255))
                                
                                # è®¡ç®—å±…ä¸­ä½ç½®
                                paste_x = (target_width - new_width) // 2
                                paste_y = (target_height - new_height) // 2
                                
                                # ç²˜è´´åˆ°æ–°ç”»å¸ƒä¸­å¿ƒ
                                new_image.paste(scaled_image, (paste_x, paste_y))
                                
                                # å¦‚æœå›¾åƒæ²¡æœ‰å®Œå…¨è¦†ç›–ç”»å¸ƒï¼Œä½¿ç”¨è¾¹ç¼˜æ‰©å±•
                                if paste_x < 0 or paste_y < 0:
                                    print(f"ğŸ”§ ä½¿ç”¨è¾¹ç¼˜æ‰©å±•å¡«å……ç©ºç™½åŒºåŸŸ")
                                    # åˆ›å»ºæ›´å¤§çš„ä¸´æ—¶ç”»å¸ƒ
                                    temp_width = max(target_width, new_width)
                                    temp_height = max(target_height, new_height)
                                    temp_image = Image.new('RGB', (temp_width, temp_height), (255, 255, 255))
                                    
                                    # å°†ç¼©æ”¾åçš„å›¾åƒå±…ä¸­æ”¾ç½®
                                    temp_paste_x = (temp_width - new_width) // 2
                                    temp_paste_y = (temp_height - new_height) // 2
                                    temp_image.paste(scaled_image, (temp_paste_x, temp_paste_y))
                                    
                                    # è£å‰ªåˆ°ç›®æ ‡å°ºå¯¸
                                    crop_x = (temp_width - target_width) // 2
                                    crop_y = (temp_height - target_height) // 2
                                    new_image = temp_image.crop((crop_x, crop_y, crop_x + target_width, crop_y + target_height))
                                
                                edited_image = new_image
                            else:
                                # æ¯”ä¾‹ç›¸åŒï¼Œç›´æ¥è°ƒæ•´å°ºå¯¸
                                edited_image = edited_image.resize((target_width, target_height), Image.Resampling.LANCZOS)
                            
                            print(f"âœ… å›¾åƒå°ºå¯¸è°ƒæ•´å®Œæˆ: {edited_image.size}")
                        else:
                            print(f"âœ… å›¾åƒå°ºå¯¸å·²ç¬¦åˆè¦æ±‚: {edited_image.size}")
                            
                    except Exception as e:
                        print(f"âš ï¸ å°ºå¯¸è°ƒæ•´å¤±è´¥: {e}, ä¿æŒåŸå§‹å°ºå¯¸")
                    
                    # å¦‚æœæ²¡æœ‰å“åº”æ–‡æœ¬ï¼Œæä¾›é»˜è®¤æ–‡æœ¬
                    if not response_text:
                        response_text = "å¤šå›¾åƒç¼–è¾‘å®Œæˆï¼è¿™æ˜¯æ ¹æ®æ‚¨çš„æŒ‡ä»¤å’Œå‚è€ƒå›¾åƒç”Ÿæˆçš„ç¼–è¾‘ç»“æœã€‚"
                        print("ğŸ“ ä½¿ç”¨é»˜è®¤å“åº”æ–‡æœ¬")
                    
                    # è½¬æ¢ä¸ºtensor
                    image_tensor = pil_to_tensor(edited_image)
                    
                    print("âœ… å¤šå›¾åƒç¼–è¾‘å®Œæˆ")
                    print(f"ğŸ“ å“åº”æ–‡æœ¬é•¿åº¦: {len(response_text)}")
                    print(f"ğŸ“ å“åº”æ–‡æœ¬å†…å®¹: {response_text[:200]}...")
                    self._push_chat(enhanced_prompt, response_text or "", unique_id)
                    return (image_tensor, response_text)
                
                # å¤„ç†é”™è¯¯å“åº”
                else:
                    print(f"âŒ HTTPçŠ¶æ€ç : {response.status_code}")
                    try:
                        error_detail = response.json()
                        print(f"âŒ é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, indent=2, ensure_ascii=False)}")
                    except:
                        print(f"âŒ é”™è¯¯æ–‡æœ¬: {response.text}")
                    
                    # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    if attempt == max_retries - 1:
                        response.raise_for_status()
                    
                    # æ™ºèƒ½ç­‰å¾…
                    delay = smart_retry_delay(attempt, response.status_code)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except requests.exceptions.RequestException as e:
                error_msg = format_error_message(e)
                print(f"âŒ è¯·æ±‚å¤±è´¥: {error_msg}")
                if attempt == max_retries - 1:
                    raise ValueError(f"APIè¯·æ±‚å¤±è´¥: {error_msg}")
                else:
                    delay = smart_retry_delay(attempt)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except Exception as e:
                error_msg = format_error_message(e)
                print(f"âŒ å¤„ç†å¤±è´¥: {error_msg}")
                raise ValueError(f"å¤šå›¾åƒç¼–è¾‘å¤±è´¥: {error_msg}")

# Node mappings
NODE_CLASS_MAPPINGS = {
    "KenChenLLMGeminiBananaTextToImageBananaNode": KenChenLLMGeminiBananaTextToImageBananaNode,
    "KenChenLLMGeminiBananaImageToImageBananaNode": KenChenLLMGeminiBananaImageToImageBananaNode,
    "KenChenLLMGeminiBananaMultimodalBananaNode": KenChenLLMGeminiBananaMultimodalBananaNode,
    "GeminiBananaMultiImageEdit": KenChenLLMGeminiBananaMultiImageEditNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "KenChenLLMGeminiBananaTextToImageBananaNode": "Gemini Banana Text to Image Banana",
    "KenChenLLMGeminiBananaImageToImageBananaNode": "Gemini Banana Image to Image Banana", 
    "KenChenLLMGeminiBananaMultimodalBananaNode": "Gemini Banana Multimodal Banana",
    "GeminiBananaMultiImageEdit": "Gemini Banana Multi Image Edit",
}

