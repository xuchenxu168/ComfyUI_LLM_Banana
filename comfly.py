import os
import json
import random
import requests
import base64
import io
import torch
import numpy as np
from PIL import Image

# --- å…¨å±€å¸¸é‡å’Œé…ç½® ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
CHATFLY_CONFIG_FILE_NAME = 'ChatFly_config.json'
IMAGE_PROMPTS_FILE_NAME = 'image_prompts.txt'
TRANSITION_PROMPTS_FILE_NAME = 'transition_prompts.txt'

# --- è¾…åŠ©å‡½æ•° ---
def _log_info(message):
    print(f"[LLM Prompt] ä¿¡æ¯ï¼š{message}")

def _log_warning(message):
    print(f"[LLM Prompt] è­¦å‘Šï¼š{message}")

def _log_error(message):
    print(f"[LLM Prompt] é”™è¯¯ï¼š{message}")

def process_input_image(image_tensor):
    """å°† ComfyUI çš„ IMAGE tensor è½¬æ¢ä¸º PIL Image"""
    try:
        # å¤„ç† 4D tensor (batch)
        if image_tensor.dim() == 4:
            image_tensor = image_tensor[0]  # å–ç¬¬ä¸€å¼ å›¾ç‰‡

        # è½¬æ¢ CHW åˆ° HWC æ ¼å¼
        if image_tensor.shape[0] in [1, 3, 4]:  # CHW æ ¼å¼
            image_np = image_tensor.permute(1, 2, 0).cpu().numpy()
        else:  # å·²ç»æ˜¯ HWC æ ¼å¼
            image_np = image_tensor.cpu().numpy()

        # å½’ä¸€åŒ–å¹¶è½¬æ¢ä¸º uint8
        if image_np.max() > 1.0:
            image_np = image_np / 255.0
        image_np = (image_np * 255).astype(np.uint8)

        # å¤„ç†é€šé“
        if len(image_np.shape) == 3:
            if image_np.shape[2] == 1:
                image_np = np.repeat(image_np, 3, axis=2)  # ç°åº¦è½¬ RGB
            elif image_np.shape[2] == 4:
                image_np = image_np[:, :, :3]  # RGBA è½¬ RGB
        elif len(image_np.shape) == 2:
            image_np = np.stack([image_np] * 3, axis=2)  # ç°åº¦è½¬ RGB

        pil_image = Image.fromarray(image_np)
        return pil_image
    except Exception as e:
        _log_error(f"å¤„ç†è¾“å…¥å›¾ç‰‡å¤±è´¥: {e}")
        return None

def image_to_base64(image, format='JPEG', quality=95):
    """å°† PIL Image è½¬æ¢ä¸º base64 å­—ç¬¦ä¸²"""
    try:
        buffer = io.BytesIO()

        # å¤„ç† JPEG çš„ alpha é€šé“
        if format.upper() == 'JPEG' and image.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', image.size, (255, 255, 255))
            if image.mode == 'P':
                image = image.convert('RGBA')
            if image.mode in ('RGBA', 'LA'):
                background.paste(image, mask=image.split()[-1])
                image = background

        image.save(buffer, format=format, quality=quality)
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    except Exception as e:
        _log_error(f"è½¬æ¢å›¾ç‰‡ä¸º base64 å¤±è´¥: {e}")
        return None

def get_chatfly_config():
    """
    å°è¯•ä»åŒç›®å½•ä¸‹çš„ ChatFly_config.json æ–‡ä»¶ä¸­è¯»å– ChatFly çš„é…ç½®ã€‚
    è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« ChatFly çš„ bot_id, session_id, tokenã€‚
    å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æ ¼å¼ä¸æ­£ç¡®ï¼Œåˆ™è¿”å›ä¸€ä¸ªç©ºå­—å…¸ã€‚
    """
    config_path = os.path.join(CURRENT_DIR, CHATFLY_CONFIG_FILE_NAME)
    try:
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return config
        else:
            return {}
    except json.JSONDecodeError:
        return {}
    except Exception as e:
        return {}

def get_prompt_api_providers():
    """
    ä»ChatFly_config.jsonä¸­è·å–æç¤ºè¯æ‰©å†™APIæä¾›è€…é…ç½®
    """
    config_path = os.path.join(CURRENT_DIR, 'ChatFly_config.json')
    try:
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)

            # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–prompt_api_providers
            if "prompt_api_providers" in config:
                return config["prompt_api_providers"]
            else:
                return {
                    "Comfly": {
                        "url": "https://ai.comfly.chat/v1",
                        "api_key": config.get("api_key", ""),
                        "api_format": "openai",
                        "models": ["gpt-4o", "gpt-4-v", "claude-sonnet-4-20250514"],
                        "description": "Comfly AIé•œåƒç«™"
                    }
                }
        else:
            return {}
    except json.JSONDecodeError:
        return {}
    except Exception as e:
        return {}

def get_provider_config(provider_name):
    """
    æ ¹æ®æä¾›è€…åç§°è·å–é…ç½®
    """
    providers = get_prompt_api_providers()
    if provider_name not in providers:
        return {}

    return providers[provider_name]

def load_prompts_from_txt(file_path, default_built_in_prompts):
    """
    ä»ç‰¹å®šæ ¼å¼çš„TXTæ–‡ä»¶åŠ è½½å¤šä¸ªæç¤ºè¯ã€‚
    æ ¼å¼è¦æ±‚ï¼šæ¯ä¸ªæç¤ºè¯ä»¥ `[æç¤ºè¯åç§°]` å¼€å¤´ï¼Œå†…å®¹åœ¨å…¶åï¼Œç›´åˆ°ä¸‹ä¸€ä¸ª `[` å¼€å¤´æˆ–æ–‡ä»¶ç»“æŸã€‚
    ç©ºè¡Œå’Œè¡Œé¦–è¡Œå°¾çš„ç©ºæ ¼ä¼šè¢«å»é™¤ã€‚
    """
    prompts = {}
    current_prompt_name = None
    current_prompt_content = []

    if not os.path.exists(file_path):
        return default_built_in_prompts

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip() # ç§»é™¤è¡Œé¦–è¡Œå°¾ç©ºç™½
                if not line: # è·³è¿‡ç©ºè¡Œ
                    continue

                if line.startswith('[') and line.endswith(']'):
                    # æ–°çš„æç¤ºè¯åç§°
                    if current_prompt_name and current_prompt_content:
                        prompts[current_prompt_name] = "\n".join(current_prompt_content).strip()

                    current_prompt_name = line[1:-1].strip() # æå–åç§°
                    current_prompt_content = [] # é‡ç½®å†…å®¹
                elif current_prompt_name is not None:
                    # æ·»åŠ å†…å®¹åˆ°å½“å‰æç¤ºè¯
                    current_prompt_content.append(line)
                # else: å¿½ç•¥æ–‡ä»¶å¼€å¤´åœ¨ç¬¬ä¸€ä¸ª [ ] ä¹‹å‰çš„è¡Œ

            # å¤„ç†æ–‡ä»¶æœ«å°¾çš„æœ€åä¸€ä¸ªæç¤ºè¯
            if current_prompt_name and current_prompt_content:
                prompts[current_prompt_name] = "\n".join(current_prompt_content).strip()

        if not prompts:
            return default_built_in_prompts

        return prompts

    except Exception as e:
        return default_built_in_prompts

# --- Comflyä¸“ç”¨èŠ‚ç‚¹ ---
class Comfly_Prompt_Expand_From_Image:
    CATEGORY = "Ken-Chen/LLM-Nano-Banana"
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("expanded_prompt",)
    FUNCTION = "expand_prompt"

    # å†…ç½®çš„é»˜è®¤è¯†å›¾æç¤ºè¯ (å½“TXTæ–‡ä»¶ä¸å­˜åœ¨æˆ–è§£æå¤±è´¥æ—¶ä½œä¸ºå¤‡ç”¨)
    _BUILT_IN_IMAGE_PROMPTS = {
        "é€šç”¨é«˜è´¨é‡è‹±æ–‡æè¿° (å†…ç½®)": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒæè¿°ä¸“å®¶ï¼Œèƒ½å¤Ÿå°†å›¾ç‰‡å†…å®¹è½¬åŒ–ä¸ºé«˜è´¨é‡çš„è‹±æ–‡æç¤ºè¯ï¼Œç”¨äºæ–‡æœ¬åˆ°å›¾åƒçš„ç”Ÿæˆæ¨¡å‹ã€‚è¯·ä»”ç»†è§‚å¯Ÿæä¾›çš„å›¾ç‰‡ï¼Œå¹¶ç”Ÿæˆä¸€æ®µè¯¦ç»†ã€å…·ä½“ã€å¯Œæœ‰åˆ›é€ æ€§çš„è‹±æ–‡çŸ­è¯­ï¼Œæè¿°å›¾ç‰‡ä¸­çš„ä¸»ä½“å¯¹è±¡ã€åœºæ™¯ã€åŠ¨ä½œã€å…‰çº¿ã€æè´¨ã€è‰²å½©ã€æ„å›¾å’Œè‰ºæœ¯é£æ ¼ã€‚è¦æ±‚ï¼šè¯­è¨€ï¼šä¸¥æ ¼ä½¿ç”¨è‹±æ–‡ã€‚ç»†èŠ‚ï¼šå°½å¯èƒ½å¤šåœ°æç»˜å›¾ç‰‡ç»†èŠ‚ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºç‰©ä½“ã€äººç‰©ã€èƒŒæ™¯ã€å‰æ™¯ã€çº¹ç†ã€è¡¨æƒ…ã€åŠ¨ä½œã€æœè£…ã€é“å…·ç­‰ã€‚è§’åº¦ï¼šå°½å¯èƒ½ä»å¤šä¸ªè§’åº¦ä¸°å¯Œæè¿°ï¼Œä¾‹å¦‚ç‰¹å†™ã€å¹¿è§’ã€ä¿¯è§†ã€ä»°è§†ç­‰ï¼Œä½†ä¸è¦ç›´æ¥å†™\"è§’åº¦\"ã€‚è¿æ¥ï¼šä½¿ç”¨é€—å·ï¼ˆ,ï¼‰è¿æ¥ä¸åŒçš„çŸ­è¯­ï¼Œå½¢æˆä¸€ä¸ªè¿è´¯çš„æç¤ºè¯ã€‚äººç‰©ï¼šæç»˜äººç‰©æ—¶ï¼Œä½¿ç”¨ç¬¬ä¸‰äººç§°ï¼ˆå¦‚ 'a woman', 'the man'ï¼‰ã€‚è´¨é‡è¯ï¼šåœ¨ç”Ÿæˆçš„æç¤ºè¯æœ«å°¾ï¼ŒåŠ¡å¿…æ·»åŠ ä»¥ä¸‹è´¨é‡å¢å¼ºè¯ï¼š', best quality, high resolution, 4k, high quality, masterpiece, photorealistic'"
    }

    @classmethod
    def get_image_prompts(cls):
        """åŠ è½½å¤–éƒ¨æˆ–å†…ç½®çš„å›¾åƒæç¤ºè¯å­—å…¸ã€‚"""
        return load_prompts_from_txt(
            os.path.join(CURRENT_DIR, IMAGE_PROMPTS_FILE_NAME),
            cls._BUILT_IN_IMAGE_PROMPTS
        )

    @classmethod
    def get_comfly_config(cls):
        return get_chatfly_config()

    @classmethod
    def INPUT_TYPES(cls):
        available_prompts = cls.get_image_prompts()
        prompt_keys = list(available_prompts.keys())
        default_selection = prompt_keys[0] if prompt_keys else "æ— å¯ç”¨æç¤ºè¯"

        # è·å–æ‰€æœ‰APIæä¾›è€…
        providers = get_prompt_api_providers()
        provider_names = list(providers.keys())
        default_provider = provider_names[0] if provider_names else "Comfly"

        # åˆå¹¶æ‰€æœ‰æä¾›è€…çš„æ¨¡å‹åˆ—è¡¨ï¼ˆå»é‡ï¼‰
        all_models = []
        seen_models = set()
        for provider_name, provider_info in providers.items():
            models = provider_info.get("models", [])
            for model in models:
                if model not in seen_models:
                    all_models.append(model)
                    seen_models.add(model)

        # å¦‚æœæ²¡æœ‰æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not all_models:
            all_models = ["gpt-4o", "gpt-4-v", "claude-sonnet-4-20250514"]

        return {
            "required": {
                "api_provider": (provider_names, {"default": default_provider, "label": "APIæä¾›è€… API Provider"}),
                "image_prompt_preset": (prompt_keys, {"default": default_selection, "label": "å›¾åƒæç¤ºè¯é¢„è®¾ Image Prompt Preset"}),
                "base_url": ("STRING", {"multiline": False, "default": "", "placeholder": "APIåœ°å€å°†è‡ªåŠ¨æ ¹æ®æä¾›è€…é€‰æ‹©ï¼ˆå¯æ‰‹åŠ¨è¦†ç›–ï¼‰", "label": "APIåœ°å€ API Base URL"}),
                "api_key": ("STRING", {"multiline": False, "default": "", "placeholder": "APIå¯†é’¥ (API Key)", "label": "APIå¯†é’¥ API Key"}),
                "model": (all_models, {"default": all_models[0] if all_models else "gpt-4o", "label": "æ¨¡å‹ Model"}),
                "system_prompt": ("STRING", {"multiline": True, "default": available_prompts.get(default_selection, ""), "placeholder": "ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯è‡ªå®šä¹‰ä¸“å®¶è§’è‰²ï¼Œæ”¯æŒä¸­æ–‡ï¼‰ System prompt (custom expert role, supports Chinese)", "label": "ç³»ç»Ÿæç¤ºè¯ System Prompt"}),
                "user_prompt": ("STRING", {"multiline": True, "default": "", "placeholder": "è¯·è¾“å…¥ä½ çš„åŸå§‹æç¤ºè¯ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰Enter your original prompt (supports Chinese)", "label": "ç”¨æˆ·æç¤ºè¯ User Prompt"}),
                "user_requirement": ("STRING", {"multiline": True, "default": "", "placeholder": "è¯·è¾“å…¥ä½ çš„é¢å¤–è¦æ±‚ï¼ˆå¯é€‰ï¼Œæ”¯æŒä¸­æ–‡ï¼‰Enter your extra requirements (optional, supports Chinese)", "label": "é¢å¤–è¦æ±‚ Extra Requirement"}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01, "label": "é‡‡æ ·æ¸©åº¦ Temperature"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff, "step": 1, "label": "éšæœºç§å­ Seed"})
            },
            "optional": {
                "image": ("IMAGE", {"label": "å‚è€ƒå›¾ç‰‡ Reference Image"}),
                "ref_image": ("STRING", {"multiline": True, "default": "", "placeholder": "Base64ç¼–ç å›¾ç‰‡ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆä½¿ç”¨imageè¾“å…¥ï¼‰", "label": "Base64å›¾ç‰‡ Base64 Image"}),
                "top_p": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0, "step": 0.01, "label": "é‡‡æ ·æ¦‚ç‡ Top-p"}),
                "max_tokens": ("INT", {"default": 400, "min": 1, "max": 4096, "label": "æœ€å¤§Tokenæ•° Max Tokens"}),
                "image_url": ("STRING", {"multiline": True, "default": "", "placeholder": "å¯å¡«å†™å›¾ç‰‡Base64æˆ–å›¾ç‰‡URL (Base64 or image URL)", "label": "image_url"})
            }
        }

    def expand_prompt(self, api_provider, image_prompt_preset, base_url, api_key, model, system_prompt, user_prompt, user_requirement, temperature=0.7, seed=0, image=None, ref_image="", top_p=0.8, max_tokens=400, image_url=""):
        import requests

        # æ ¹æ®APIæä¾›è€…è·å–é…ç½®
        config = get_provider_config(api_provider)

        # ä»é…ç½®ä¸­è·å–URLå’ŒAPI key
        final_base_url = base_url.strip() or config.get("url", "")
        final_api_key = api_key.strip() or config.get("api_key", "")

        if not final_base_url or not final_api_key:
            return (f"æœªæ£€æµ‹åˆ°API Keyæˆ–Base URLï¼Œè¯·åœ¨èŠ‚ç‚¹è¾“å…¥æ¡†å¡«å†™ï¼Œæˆ–åœ¨ChatFly_config.jsonçš„prompt_api_providersä¸­é…ç½®{api_provider}çš„urlå’Œapi_keyã€‚\nAPI Key or Base URL not found. Please fill in the node input box, or configure url and api_key for {api_provider} in ChatFly_config.json's prompt_api_providers.",)
        api_url = final_base_url.rstrip("/") + "/chat/completions"
        headers = {
            "Authorization": f"Bearer {final_api_key}",
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        available_prompts = self.get_image_prompts()
        preset_prompt = available_prompts.get(image_prompt_preset, "")
        final_system_prompt = system_prompt.strip() or preset_prompt
        content_parts = []
        if final_system_prompt:
            content_parts.append({"type": "text", "text": final_system_prompt})
        if user_prompt.strip():
            content_parts.append({"type": "text", "text": user_prompt.strip()})
        if user_requirement.strip():
            content_parts.append({"type": "text", "text": user_requirement.strip()})

        # å¤„ç†å›¾ç‰‡è¾“å…¥ï¼ˆä¼˜å…ˆçº§ï¼šimage > image_url > ref_imageï¼‰
        image_base64 = None
        has_image = False

        # 1. ä¼˜å…ˆä½¿ç”¨ IMAGE ç±»å‹è¾“å…¥
        if image is not None:
            pil_image = process_input_image(image)
            if pil_image:
                image_base64 = image_to_base64(pil_image, format='JPEG', quality=95)
                if image_base64:
                    has_image = True

        # 2. å…¶æ¬¡ä½¿ç”¨ image_url
        elif image_url and image_url.strip():
            url_val = image_url.strip()
            if url_val.startswith("http://") or url_val.startswith("https://"):
                content_parts.append({"type": "image_url", "image_url": {"url": url_val}})
                has_image = True
            else:
                # éªŒè¯ base64 æ•°æ®çš„æœ‰æ•ˆæ€§
                try:
                    base64.b64decode(url_val, validate=True)
                    image_base64 = url_val
                    has_image = True
                except Exception:
                    pass  # æ— æ•ˆçš„base64ï¼Œå¿½ç•¥

        # 3. æœ€åä½¿ç”¨ ref_image
        elif ref_image and ref_image.strip():
            ref_image_val = ref_image.strip()
            # éªŒè¯ base64 æ•°æ®çš„æœ‰æ•ˆæ€§
            try:
                base64.b64decode(ref_image_val, validate=True)
                image_base64 = ref_image_val
                has_image = True
            except Exception:
                pass  # æ— æ•ˆçš„base64ï¼Œå¿½ç•¥

        # æ·»åŠ  base64 å›¾ç‰‡åˆ°å†…å®¹
        if image_base64:
            content_parts.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}})

        messages = [{"role": "user", "content": content_parts}]
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "top_p": top_p,
            "max_tokens": max_tokens,
            "stream": False
        }

        try:
            resp = requests.post(api_url, json=payload, headers=headers, timeout=60)

            resp.raise_for_status()
            data = resp.json()
            expanded_prompt = data["choices"][0]["message"]["content"]
            return (expanded_prompt,)
        except requests.exceptions.HTTPError as e:
            error_message = f"{api_provider} API HTTPé”™è¯¯: {e}\nçŠ¶æ€ç : {resp.status_code}"
            if resp.status_code == 500:
                error_message += "\nğŸ’¡ æç¤º: 500é”™è¯¯é€šå¸¸æ˜¯æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œå¯èƒ½åŸå› ï¼š"
                error_message += "\n   1. æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼ˆè¯·å°è¯•æ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼Œå¦‚ gpt-4-v, gemini-2.5-flash ç­‰ï¼‰"
                error_message += "\n   2. å›¾ç‰‡base64æ•°æ®æ ¼å¼é—®é¢˜"
                error_message += "\n   3. è¯·æ±‚ä½“æ ¼å¼ä¸ç¬¦åˆAPIè¦æ±‚"
                error_message += "\n   4. APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
                try:
                    error_detail = resp.json()
                    error_message += f"\n   æœåŠ¡å™¨è¿”å›: {json.dumps(error_detail, indent=2, ensure_ascii=False)}"
                except:
                    pass
            _log_error(error_message)
            return (error_message,)
        except Exception as e:
            error_message = f"{api_provider} API è°ƒç”¨å¤±è´¥: {e}\n{api_provider} API call failed: {e}"
            _log_error(error_message)
            return (error_message,)

# --- é¦–å°¾å¸§æç¤ºè¯ç”ŸæˆèŠ‚ç‚¹ ---
class Comfly_First_Last_Frame_Prompt:
    """
    é¦–å°¾å¸§è¿‡æ¸¡æç¤ºè¯ç”ŸæˆèŠ‚ç‚¹
    æ ¹æ®é¦–å¸§å’Œå°¾å¸§å›¾ç‰‡ç”Ÿæˆæè¿°æ•´ä¸ªè¿‡æ¸¡è¿‡ç¨‹çš„é«˜è´¨é‡æç¤ºè¯
    ç”¨äºè§†é¢‘ç”ŸæˆèŠ‚ç‚¹ç”Ÿæˆé¦–å¸§åˆ°å°¾å¸§çš„è¿ç»­æ€§è§†é¢‘
    """
    CATEGORY = "Ken-Chen/LLM-Nano-Banana"
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("transition_prompt",)
    FUNCTION = "generate_transition_prompt"

    # é¦–å°¾å¸§è¿‡æ¸¡æç¤ºè¯ç³»ç»Ÿæç¤ºè¯
    _FIRST_LAST_FRAME_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘è¿‡æ¸¡åˆ†æå’Œæç¤ºè¯ç”Ÿæˆä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æè§†é¢‘çš„é¦–å¸§å’Œå°¾å¸§å›¾ç‰‡ï¼Œç”Ÿæˆä¸€ä¸ªé«˜è´¨é‡çš„è‹±æ–‡æç¤ºè¯ï¼Œç”¨äºæè¿°ä»é¦–å¸§åˆ°å°¾å¸§çš„æ•´ä¸ªè¿‡æ¸¡è¿‡ç¨‹å’ŒåŠ¨æ€å˜åŒ–ã€‚

ã€æ ¸å¿ƒä»»åŠ¡ã€‘
æ ¹æ®é¦–å¸§ï¼ˆåˆå§‹çŠ¶æ€ï¼‰å’Œå°¾å¸§ï¼ˆæœ€ç»ˆçŠ¶æ€ï¼‰ä¸¤å¼ å›¾ç‰‡ï¼Œç”Ÿæˆä¸€ä¸ªå•ä¸€çš„ã€è¿è´¯çš„ã€æè¿°æ•´ä¸ªè¿‡æ¸¡è¿‡ç¨‹çš„æç¤ºè¯ã€‚è¿™ä¸ªæç¤ºè¯å°†ç”¨äºè§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œç”Ÿæˆä»é¦–å¸§å¹³æ»‘è¿‡æ¸¡åˆ°å°¾å¸§çš„è¿ç»­æ€§è§†é¢‘ã€‚

ã€é¦–å¸§åˆ†æã€‘
é¦–å¸§æ˜¯è§†é¢‘çš„å¼€å§‹ç”»é¢ï¼Œä»£è¡¨åˆå§‹çŠ¶æ€ã€‚è¯·åˆ†æï¼š
- ä¸»ä½“å¯¹è±¡çš„åˆå§‹çŠ¶æ€ã€ä½ç½®ã€å§¿æ€å’Œå¤–è§‚
- åœºæ™¯çš„åˆå§‹ç¯å¢ƒã€èƒŒæ™¯ã€å…‰çº¿å’Œæ°›å›´
- è‰²å½©æ–¹æ¡ˆå’Œè§†è§‰é£æ ¼
- ç›¸æœºè§’åº¦å’Œæ„å›¾
- æ‰€æœ‰å…³é”®çš„è§†è§‰å…ƒç´ 

ã€å°¾å¸§åˆ†æã€‘
å°¾å¸§æ˜¯è§†é¢‘çš„ç»“æŸç”»é¢ï¼Œä»£è¡¨æœ€ç»ˆçŠ¶æ€ã€‚è¯·åˆ†æï¼š
- ä¸»ä½“å¯¹è±¡çš„æœ€ç»ˆçŠ¶æ€ã€ä½ç½®ã€å§¿æ€å’Œå¤–è§‚
- åœºæ™¯çš„æœ€ç»ˆç¯å¢ƒã€èƒŒæ™¯ã€å…‰çº¿å’Œæ°›å›´
- è‰²å½©æ–¹æ¡ˆå’Œè§†è§‰é£æ ¼
- ç›¸æœºè§’åº¦å’Œæ„å›¾
- æ‰€æœ‰å…³é”®çš„è§†è§‰å…ƒç´ 

ã€è¿‡æ¸¡åˆ†æã€‘
æ¯”è¾ƒé¦–å¸§å’Œå°¾å¸§ï¼Œè¯†åˆ«æ‰€æœ‰çš„å˜åŒ–å’Œè¿‡æ¸¡ï¼š
- ä¸»ä½“å¯¹è±¡çš„è¿åŠ¨æ–¹å‘å’Œè½¨è¿¹
- ä¸»ä½“å¯¹è±¡çš„å½¢æ€ã€å¤§å°æˆ–å¤–è§‚çš„å˜åŒ–
- åœºæ™¯èƒŒæ™¯çš„å˜åŒ–
- å…‰çº¿ã€è‰²å½©ã€æ°›å›´çš„æ¼”å˜
- ç›¸æœºçš„è¿åŠ¨ï¼ˆå¹³ç§»ã€ç¼©æ”¾ã€æ—‹è½¬ç­‰ï¼‰
- æ•´ä¸ªè§†é¢‘çš„åŠ¨æ€èŠ‚å¥å’Œæµç•…æ€§

ã€æç¤ºè¯ç”Ÿæˆè§„åˆ™ã€‘
1. è¯­è¨€ï¼šä¸¥æ ¼ä½¿ç”¨è‹±æ–‡
2. æ ¼å¼ï¼šä½¿ç”¨é€—å·ï¼ˆ,ï¼‰è¿æ¥ä¸åŒçš„çŸ­è¯­ï¼Œå½¢æˆä¸€ä¸ªè¿è´¯çš„ã€æµç•…çš„æç¤ºè¯
3. æ—¶é—´æ€§ï¼šä½¿ç”¨åŠ¨è¯å’ŒåŠ¨ä½œè¯æ±‡æ¥æè¿°è¿‡ç¨‹å’Œå˜åŒ–ï¼Œä¾‹å¦‚ï¼š
   - "transitioning from ... to ..."
   - "gradually changing from ... to ..."
   - "smoothly moving from ... to ..."
   - "evolving from ... to ..."
4. è¿è´¯æ€§ï¼šç¡®ä¿æç¤ºè¯æè¿°çš„æ˜¯ä¸€ä¸ªè¿ç»­çš„ã€å¹³æ»‘çš„è¿‡æ¸¡è¿‡ç¨‹ï¼Œè€Œä¸æ˜¯ä¸¤ä¸ªç‹¬ç«‹çš„çŠ¶æ€
5. ç»†èŠ‚ï¼šè¯¦ç»†æç»˜ï¼š
   - ä¸»ä½“å¯¹è±¡çš„è¿åŠ¨å’Œå˜åŒ–
   - èƒŒæ™¯å’Œç¯å¢ƒçš„æ¼”å˜
   - å…‰çº¿ã€è‰²å½©ã€æ°›å›´çš„è¿‡æ¸¡
   - ç›¸æœºçš„è¿åŠ¨ï¼ˆå¦‚æœæœ‰ï¼‰
   - æ•´ä¸ªè¿‡ç¨‹çš„èŠ‚å¥å’Œæµç•…æ€§
6. äººç‰©æè¿°ï¼šä½¿ç”¨ç¬¬ä¸‰äººç§°ï¼ˆå¦‚ 'a woman', 'the man', 'a person'ï¼‰
7. è´¨é‡è¯ï¼šåœ¨æç¤ºè¯æœ«å°¾ï¼ŒåŠ¡å¿…æ·»åŠ ä»¥ä¸‹è´¨é‡å¢å¼ºè¯ï¼š
   ', best quality, high resolution, 4k, high quality, masterpiece, photorealistic, smooth transition, seamless motion'

ã€è¾“å‡ºæ ¼å¼ã€‘
ç”Ÿæˆä¸€ä¸ªå•ä¸€çš„ã€å®Œæ•´çš„ã€é«˜è´¨é‡çš„è‹±æ–‡æç¤ºè¯ï¼Œç”¨äºæè¿°ä»é¦–å¸§åˆ°å°¾å¸§çš„æ•´ä¸ªè¿‡æ¸¡è¿‡ç¨‹ã€‚è¿™ä¸ªæç¤ºè¯åº”è¯¥èƒ½å¤ŸæŒ‡å¯¼è§†é¢‘ç”Ÿæˆæ¨¡å‹ç”Ÿæˆå¹³æ»‘ã€è¿è´¯çš„è¿‡æ¸¡è§†é¢‘ã€‚

ã€ç¤ºä¾‹ã€‘
é¦–å¸§ï¼šä¸€ä¸ªäººç«™åœ¨æˆ¿é—´çš„å·¦è¾¹ï¼Œå…‰çº¿æ˜æš—
å°¾å¸§ï¼šåŒä¸€ä¸ªäººç«™åœ¨æˆ¿é—´çš„å³è¾¹ï¼Œå…‰çº¿æ˜äº®
è¾“å‡ºæç¤ºè¯ï¼ša person smoothly walking from the left side to the right side of a room, transitioning from dim lighting to bright lighting, the camera follows the movement, the background gradually becomes brighter, best quality, high resolution, 4k, high quality, masterpiece, photorealistic, smooth transition, seamless motion"""

    @classmethod
    def get_comfly_config(cls):
        return get_chatfly_config()

    @classmethod
    def INPUT_TYPES(cls):
        # è·å–æ‰€æœ‰APIæä¾›è€…
        providers = get_prompt_api_providers()
        provider_names = list(providers.keys())
        default_provider = provider_names[0] if provider_names else "Comfly"

        # åˆå¹¶æ‰€æœ‰æä¾›è€…çš„æ¨¡å‹åˆ—è¡¨ï¼ˆå»é‡ï¼‰
        all_models = []
        seen_models = set()
        for provider_name, provider_info in providers.items():
            models = provider_info.get("models", [])
            for model in models:
                if model not in seen_models:
                    all_models.append(model)
                    seen_models.add(model)

        # å¦‚æœæ²¡æœ‰æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not all_models:
            all_models = ["gpt-4o", "gpt-4-v", "claude-sonnet-4-20250514"]

        return {
            "required": {
                "api_provider": (provider_names, {"default": default_provider, "label": "APIæä¾›è€… API Provider"}),
                "base_url": ("STRING", {"multiline": False, "default": "", "placeholder": "APIåœ°å€å°†è‡ªåŠ¨æ ¹æ®æä¾›è€…é€‰æ‹©ï¼ˆå¯æ‰‹åŠ¨è¦†ç›–ï¼‰", "label": "APIåœ°å€ API Base URL"}),
                "api_key": ("STRING", {"multiline": False, "default": "", "placeholder": "APIå¯†é’¥ (API Key)", "label": "APIå¯†é’¥ API Key"}),
                "model": (all_models, {"default": all_models[0] if all_models else "gpt-4o", "label": "æ¨¡å‹ Model"}),
                "first_frame": ("IMAGE", {"label": "é¦–å¸§å›¾ç‰‡ First Frame Image"}),
                "last_frame": ("IMAGE", {"label": "å°¾å¸§å›¾ç‰‡ Last Frame Image"}),
                "system_prompt": ("STRING", {"multiline": True, "default": cls._FIRST_LAST_FRAME_SYSTEM_PROMPT, "placeholder": "ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯è‡ªå®šä¹‰ï¼Œæ”¯æŒä¸­æ–‡ï¼‰System prompt (customizable, supports Chinese)", "label": "ç³»ç»Ÿæç¤ºè¯ System Prompt"}),
                "user_requirement": ("STRING", {"multiline": True, "default": "", "placeholder": "è¯·è¾“å…¥ä½ çš„é¢å¤–è¦æ±‚ï¼ˆå¯é€‰ï¼Œæ”¯æŒä¸­æ–‡ï¼‰Enter your extra requirements (optional, supports Chinese)", "label": "é¢å¤–è¦æ±‚ Extra Requirement"}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01, "label": "é‡‡æ ·æ¸©åº¦ Temperature"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff, "step": 1, "label": "éšæœºç§å­ Seed"})
            },
            "optional": {
                "top_p": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0, "step": 0.01, "label": "é‡‡æ ·æ¦‚ç‡ Top-p"}),
                "max_tokens": ("INT", {"default": 800, "min": 1, "max": 4096, "label": "æœ€å¤§Tokenæ•° Max Tokens"})
            }
        }

    def generate_transition_prompt(self, api_provider, base_url, api_key, model, first_frame, last_frame, system_prompt, user_requirement, temperature=0.7, seed=0, top_p=0.8, max_tokens=600):
        import requests

        # æ ¹æ®APIæä¾›è€…è·å–é…ç½®
        config = get_provider_config(api_provider)
        _log_info(f"ä½¿ç”¨APIæä¾›è€…: {api_provider}")

        # ä»é…ç½®ä¸­è·å–URLå’ŒAPI key
        final_base_url = base_url.strip() or config.get("url", "")
        final_api_key = api_key.strip() or config.get("api_key", "")

        if not final_base_url or not final_api_key:
            return (f"æœªæ£€æµ‹åˆ°API Keyæˆ–Base URLï¼Œè¯·åœ¨èŠ‚ç‚¹è¾“å…¥æ¡†å¡«å†™ï¼Œæˆ–åœ¨ChatFly_config.jsonçš„prompt_api_providersä¸­é…ç½®{api_provider}çš„urlå’Œapi_keyã€‚\nAPI Key or Base URL not found. Please fill in the node input box, or configure url and api_key for {api_provider} in ChatFly_config.json's prompt_api_providers.",)

        api_url = final_base_url.rstrip("/") + "/chat/completions"
        headers = {
            "Authorization": f"Bearer {final_api_key}",
            "Content-Type": "application/json",
            "Accept": "application/json"
        }

        # å¤„ç†é¦–å¸§å›¾ç‰‡
        first_frame_pil = process_input_image(first_frame)
        if not first_frame_pil:
            return ("é¦–å¸§å›¾ç‰‡å¤„ç†å¤±è´¥ Failed to process first frame image",)
        first_frame_base64 = image_to_base64(first_frame_pil, format='JPEG', quality=95)
        if not first_frame_base64:
            return ("é¦–å¸§å›¾ç‰‡è½¬æ¢ä¸ºbase64å¤±è´¥ Failed to convert first frame to base64",)

        # å¤„ç†å°¾å¸§å›¾ç‰‡
        last_frame_pil = process_input_image(last_frame)
        if not last_frame_pil:
            return ("å°¾å¸§å›¾ç‰‡å¤„ç†å¤±è´¥ Failed to process last frame image",)
        last_frame_base64 = image_to_base64(last_frame_pil, format='JPEG', quality=95)
        if not last_frame_base64:
            return ("å°¾å¸§å›¾ç‰‡è½¬æ¢ä¸ºbase64å¤±è´¥ Failed to convert last frame to base64",)

        # æ„å»ºå†…å®¹
        content_parts = [
            {"type": "text", "text": system_prompt},
            {"type": "text", "text": "ã€é¦–å¸§å›¾ç‰‡ã€‘\nè¯·åˆ†æä»¥ä¸‹é¦–å¸§å›¾ç‰‡ï¼ˆè§†é¢‘çš„å¼€å§‹ç”»é¢ï¼‰ï¼š"},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{first_frame_base64}"}},
            {"type": "text", "text": "ã€å°¾å¸§å›¾ç‰‡ã€‘\nè¯·åˆ†æä»¥ä¸‹å°¾å¸§å›¾ç‰‡ï¼ˆè§†é¢‘çš„ç»“æŸç”»é¢ï¼‰ï¼š"},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{last_frame_base64}"}},
            {"type": "text", "text": "è¯·ç”Ÿæˆä¸€ä¸ªå•ä¸€çš„ã€é«˜è´¨é‡çš„è‹±æ–‡æç¤ºè¯ï¼Œç”¨äºæè¿°ä»é¦–å¸§åˆ°å°¾å¸§çš„æ•´ä¸ªè¿‡æ¸¡è¿‡ç¨‹ã€‚è¿™ä¸ªæç¤ºè¯å°†ç”¨äºè§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œç”Ÿæˆä»é¦–å¸§å¹³æ»‘è¿‡æ¸¡åˆ°å°¾å¸§çš„è¿ç»­æ€§è§†é¢‘ã€‚"}
        ]

        if user_requirement.strip():
            content_parts.append({"type": "text", "text": f"ã€é¢å¤–è¦æ±‚ã€‘\n{user_requirement.strip()}"})

        messages = [{"role": "user", "content": content_parts}]
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "top_p": top_p,
            "max_tokens": max_tokens,
            "stream": False
        }

        try:
            resp = requests.post(api_url, json=payload, headers=headers, timeout=60)

            resp.raise_for_status()
            data = resp.json()
            response_text = data["choices"][0]["message"]["content"]

            # è¿”å›è¿‡æ¸¡æç¤ºè¯
            return (response_text,)

        except requests.exceptions.HTTPError as e:
            error_message = f"{api_provider} API HTTPé”™è¯¯: {e}\nçŠ¶æ€ç : {resp.status_code}"
            if resp.status_code == 500:
                error_message += "\nğŸ’¡ æç¤º: 500é”™è¯¯é€šå¸¸æ˜¯æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œå¯èƒ½åŸå› ï¼š"
                error_message += "\n   1. æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼ˆè¯·å°è¯•æ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼Œå¦‚ gpt-4-v ç­‰ï¼‰"
                error_message += "\n   2. å›¾ç‰‡base64æ•°æ®æ ¼å¼é—®é¢˜"
                error_message += "\n   3. è¯·æ±‚ä½“æ ¼å¼ä¸ç¬¦åˆAPIè¦æ±‚"
                error_message += "\n   4. APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
                try:
                    error_detail = resp.json()
                    error_message += f"\n   æœåŠ¡å™¨è¿”å›: {json.dumps(error_detail, indent=2, ensure_ascii=False)}"
                except:
                    pass
            _log_error(error_message)
            return (error_message,)
        except Exception as e:
            error_message = f"{api_provider} API è°ƒç”¨å¤±è´¥: {e}\n{api_provider} API call failed: {e}"
            _log_error(error_message)
            return (error_message,)


# --- æ³¨å†ŒèŠ‚ç‚¹ ---
NODE_CLASS_MAPPINGS = {
    "Comfly_Prompt_Expand_From_Image": Comfly_Prompt_Expand_From_Image,
    "Comfly_First_Last_Frame_Prompt": Comfly_First_Last_Frame_Prompt,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Comfly_Prompt_Expand_From_Image": "æ‰©å†™é«˜è´¨é‡æç¤ºè¯ (Comfly/T8)",
    "Comfly_First_Last_Frame_Prompt": "é¦–å°¾å¸§è¿‡æ¸¡æç¤ºè¯ç”Ÿæˆ (Comfly/T8)",
}